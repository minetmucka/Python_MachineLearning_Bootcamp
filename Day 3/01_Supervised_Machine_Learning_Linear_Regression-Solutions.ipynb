{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Outline\n",
    "\n",
    "* **Machine learning terminology review**\n",
    "* **Data cleaning and prep for regression**\n",
    "* **Univariate linear regression**\n",
    "* **Multivariate linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we've just been exploring data. Generating statistical summaries of different rows and columns in our datasets is useful and helps us answer certain kinds of questions about historical trends we see, but it gets us nowhere when we want to **predict** something useful using our data in the future. We've been doing description, but now we are going to move on to prediction.\n",
    "\n",
    "Before we get started with actual machine learning, we need to understand some of the language used to describe the classes of problems that machine learning can be used to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the machine learning universe there are two kinds of problems:\n",
    "  * **Supervised learning problems** involve constructing an accurate model that can **predict some kind of an outcome when past data has labels for those outcomes**. [supervised learning wikipedia page](https://en.wikipedia.org/wiki/Supervised_learning)\n",
    "  * **Unsupervised learning problems** involve constructing models where labels on historical data are unavailable. [unsupervised learning wikipedia page](https://en.wikipedia.org/wiki/Unsupervised_learning)\n",
    "\n",
    "Today we will be talking about two **supervised learning** approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the universe of supervised machine learning problems, there exist two distinct classes of problems.\n",
    "\n",
    "These classes are based completely on the kind of value or values we are trying to predict:\n",
    "  * A **classification problem** is a **supervised learning problem** where the objective is to learn to predict a categorical value.\n",
    "  * A **regression problem** is a **supervised learning problem** where the objective is to learn to predict a continuous value.\n",
    "\n",
    "We will start with learning about **linear regression**, a machine learning modeling approach that has classically been used for **regression** problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression has been used extensively for a whole myriad of distinct regression problems in the past. \n",
    "\n",
    "Linear regression is the first model that we will learn because:\n",
    "  * it is widely used\n",
    "  * is very quick and easy to set up\n",
    "  * a trained linear regression model is very easy to understand.\n",
    "  \n",
    "Really, it's critical to understand linear regression because it is the foundational machine learning modeling approach on which many other methods are based.\n",
    "\n",
    "By the end of this notebook you will:\n",
    "\n",
    "- Have a working conceptual understanding of linear regression and become familiar with some key terminology\n",
    "- Be able to apply linear regression to a machine learning problem using scikit-learn\n",
    "- Be able to interpret linear regression model coefficients\n",
    "- Be able to apply three different evaluation metrics for regression\n",
    "- Be able to use train/test split to estimate model performance on unseen data \n",
    "- Be able to articulate the strengths and weaknesses of linear regression\n",
    "\n",
    "We will be using the default machine learning library in **Python**, [scikit-learn](http://scikit-learn.org/stable/), which has all of the functionality we will need to explore linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing all of the functionality we will need for this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:19.558546Z",
     "start_time": "2019-02-11T00:51:18.041548Z"
    }
   },
   "outputs": [],
   "source": [
    "#data handling/modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make graphics vector graphics -- less pixelation!\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the car dataset\n",
    "\n",
    "Now that we've got all of the libraries we need, lets get some data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:21.990654Z",
     "start_time": "2019-02-11T00:51:21.958864Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "source_url = \"data/auto-mpg.data.txt\"\n",
    "\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin', 'name']\n",
    "data = pd.read_csv(source_url, names=column_names)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:28.173506Z",
     "start_time": "2019-02-11T00:51:28.167770Z"
    }
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:29.355835Z",
     "start_time": "2019-02-11T00:51:29.342195Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh: clearly there's an issue with this file! Let's take a look at it and try to diagnose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:31.039656Z",
     "start_time": "2019-02-11T00:51:31.006726Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$source_url\"\n",
    "less $1 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look through the [Pandas `read_csv` documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). Try to figure out the argument to use to read the file in properly (hint: there's just one key argument that will allow you to read the file in properly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:33.997316Z",
     "start_time": "2019-02-11T00:51:33.988735Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "data=pd.read_csv(source_url, names=column_names, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:35.922667Z",
     "start_time": "2019-02-11T00:51:35.911605Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:51:37.264074Z",
     "start_time": "2019-02-11T00:51:37.256545Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in this dataset, called an **observation** represents **one car model** (398 models in the dataset).\n",
    "\n",
    "Our goal will be to try to build a model that, when given some features describing a car model, can accurately predict the expected mpg of the vehicle.\n",
    "\n",
    "What are the **features**? (What data can we use to generate our prediction?)\n",
    "\n",
    "- **cylinders:** The number of cylinders in the model (numeric discrete)\n",
    "- **displacement:** [engine displacement](https://en.wikipedia.org/wiki/Engine_displacement) (continuous)\n",
    "- **horsepower:** horsepower of the model (continuous)\n",
    "- **weight:** total weight of the car (continuous)\n",
    "- **acceleration:** The vehicle acceleration rate of the model (continuous)\n",
    "- **origin:** The car's \"origin\" (more on this later) (categorical)\n",
    "- **name:** The car's name (text)\n",
    "\n",
    "What is the **response**? (What are we trying to predict?)\n",
    "\n",
    "- **mpg:** approximate miles per gallon of the model (continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should immediately have questions about the data\n",
    "\n",
    "1. Is there a relationship between any of the properties of the car models in our dataset?\n",
    "2. How strong is that relationship?\n",
    "3. Do any of the properties of the cars seem to relate to its mpg?\n",
    "4. What is the effect of each car attribute on mpg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll focus on exploratory data analysis pertaining to _continuous_ variables. We'll discuss categorical variables in an upcoming deck and leave it as an exercise to work on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize relationships among the features and the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quickest, most effective way you can quickly see if any of the features correlate with your response is to use a **scatter plot** to visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:52:04.098359Z",
     "start_time": "2019-02-11T00:52:03.102621Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, x_vars=['cylinders','displacement','horsepower'], y_vars='mpg', height=3, aspect=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just tried to see if there was any relationship between cylinders/displacement/horsepower and mpg for each feature by itself. Looks like all 3 are negatively correlated with mpg.\n",
    "\n",
    "If we wanted to see what the simple linear regression on each feature by itself looks like (we will get to what that actually is shortly), we can plot a regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:13:06.145722Z",
     "start_time": "2018-11-22T00:13:03.803371Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, x_vars=['cylinders','displacement','horsepower'], y_vars='mpg', height=3, aspect=0.8, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah hah! Looks like we've got another error. Reading the error message, it looks like one of the columns we are trying to plot - \"cylinders\", \"displacement\", or \"horsepower\" - are being interpreted as a string. Let's confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:53:26.127289Z",
     "start_time": "2019-02-11T00:53:26.121107Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, looks like `horsepower` is being interpreted as a string. Let's try to convert it to a `float` and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:53:28.471783Z",
     "start_time": "2019-02-11T00:53:28.197385Z"
    }
   },
   "outputs": [],
   "source": [
    "data['horsepower'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah hah - this error message tells us there is a \"?\" in the column. This is our first example of a **missing value**. \n",
    "\n",
    "For numerical columns, there are 3 common strategies for filling in missing values:\n",
    "\n",
    "1. Fill in using the mean\n",
    "2. Fill in using the median (when many outliers are present)\n",
    "3. Fill in with some default value (e.g. 0).\n",
    "\n",
    "Here, let's plot a histogram of the horsepower column without the \"?\"s to see if it is normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:53:49.314352Z",
     "start_time": "2019-02-11T00:53:49.179501Z"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[data['horsepower'] != \"?\", 'horsepower'].astype(float).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it is skewed right. Imputing the median, rather than the mean, is likely a good way to impute these missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we clean any sort of data, however, it is a good idea to know how much we are altering our original data. Here, that means checking what percent of the `horsepower` values are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:53:56.650002Z",
     "start_time": "2019-02-11T00:53:56.645652Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.sum(data['horsepower'] == '?'))\n",
    "print(data['horsepower'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 6 out of 398! It is safe to just replace these values with the median of the rest of the values in the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:55:18.922515Z",
     "start_time": "2019-02-11T00:55:18.884758Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = data['horsepower'] != \"?\"\n",
    "data_horsepower_numeric = data['horsepower'][mask].astype(float)\n",
    "data['horsepower'] = data['horsepower'].replace(\"?\", np.median(data_horsepower_numeric))\n",
    "data['horsepower'] = data['horsepower'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a **scatter matrix** to visualize the relationship between all numerical variables using the `pairplot` functionality in [seaborn](https://stanford.edu/~mwaskom/software/seaborn/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:55:34.140654Z",
     "start_time": "2019-02-11T00:55:25.384032Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.drop('name',axis=1).corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all of these columns make sense to include in the `pairplot`? If not, how could we clean our data so we're not including a column erroneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:15:32.627364Z",
     "start_time": "2018-11-22T00:15:32.621611Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(\"origin\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the scatter matrix is square and symmetric, so the plots on either side of the diagonal are mirror images of each other.\n",
    "\n",
    "It's only necessary to look at all of the plots on one side of the diagonal to see the relationships among all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also use a **correlation matrix** to compute the pairwise correlations between all numeric variables.\n",
    "\n",
    "Let's first just compute and inspect the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:15:35.517510Z",
     "start_time": "2018-11-22T00:15:35.495936Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_correlations = data.corr()\n",
    "auto_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets visualize the correlations using a `heatmap` to get a more \"visual\" understanding of the correlations among the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:15:38.329154Z",
     "start_time": "2018-11-22T00:15:38.120259Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(auto_correlations, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap representation of the correlation matrix, we can quickly tell that cylinders, displacement, horespower, and weight are positively correlated, and are all anti-correlated with both acceleration and mpg (which themselves are weakly correlated).\n",
    "\n",
    "Some of this should come as no suprise, when you think about it. The heavier a car is, the larger its engine, the larger its horsepower, the lower its mpg should be.\n",
    "\n",
    "Ok, enough exploring. We will save the changes that we made to the auto data, and then model it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:43.758140Z",
     "start_time": "2018-11-22T00:17:43.741624Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"data/mpg_cars_clean.csv\", \n",
    "            index=False, \n",
    "            columns=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Stops here\n",
    "\n",
    "# Now modeling (with sklearn) begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression on one variable (simple linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression on one variable (simple linear regression) is an approach for predicting a **continuous response** using a **single feature**. Here's the mathy way of representing a simple linear regression model:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are called the **model coefficients**. They are the values of the model that we are going to attempt to estimate to maximize $y$.\n",
    "\n",
    "$\\beta_0$ is also called the bias (its an offset), and is equivalent to the y-intercept of the model\n",
    "\n",
    "(remember $y = mx + b$ from grade school? $m=\\beta_1$ and $b=\\beta_0$ here).\n",
    "\n",
    "So, **our model must \"learn\" the values of these coefficients, and once we've learned these coefficients, we can use the model to predict mpg.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating (\"learning\") simple linear regression model coefficients\n",
    "\n",
    "Coefficients are estimated during the model fitting process using the **least squares criterion**.\n",
    "\n",
    "We will find the line (using math) which minimizes the **sum of squared errors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estimating coefficients](./images/least_squares.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following in the diagram:\n",
    "  * The black dots are the **observed values** of x and y.\n",
    "  * The thin black line is our **least squares line**.\n",
    "  * The red line is an example **residual** or **error**, which is the distance between an observed value and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the model coefficients relate to the least squares line?\n",
    "\n",
    "- $\\beta_0$ is the **intercept** (the value of $y$ when $x$=0)\n",
    "- $\\beta_1$ is the **slope** ($\\Delta y/\\Delta x$)\n",
    "\n",
    "Let's estimate the model coefficients for our car data where we will use the `acceleration` of the car as our single feature to predict `mpg`.\n",
    "\n",
    "We will use `scikit-learn` for the first time here and work through the process of training a scikit-learn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:15:47.111083Z",
     "start_time": "2018-11-22T00:15:47.095308Z"
    }
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['acceleration']\n",
    "X = data[feature_cols]\n",
    "y = data.mpg\n",
    "\n",
    "# instantiate and fit\n",
    "acc_linreg = LinearRegression()\n",
    "acc_linreg.fit(X, y)\n",
    "\n",
    "# print the coefficients\n",
    "print(\"The y intercept:\", acc_linreg.intercept_)\n",
    "print(\"The single coefficient:\", acc_linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so what did we do here?\n",
    "\n",
    "1. We created a matrix `X` that held our features and a vector `y` that held our response variable across all the observations in our dataset.\n",
    "1. We then instantiated (created) a `LinearRegression` model. \n",
    "1. However, that model was initially untrained (didn't have our data fit to it). In order to do that, we had to call the `fit` method of the `LinearRegression` object `acc_linreg` we had just created using our features `X` and outcome `y` as input parameters.\n",
    "1. After we called `fit` on our model, the simple linear regression model was fit (using math we don't have to worry about). Following this, we inspected our two coefficients.\n",
    "  \n",
    "Just to hammer all of this home, let's take a look at what this \"visually\" looks like using `pairplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:15:53.946269Z",
     "start_time": "2018-11-22T00:15:53.640289Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data,x_vars=['acceleration'],y_vars='mpg',size=6, aspect=0.8,kind='reg')\n",
    "plt.xlim(0,)\n",
    "plt.ylim(0,); # Suppress output telling us what the ylimits are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to interpret model coefficients\n",
    "\n",
    "So, now that we've got a fitted linear regression model, how do we interpret the acceleration coefficient ($\\beta_1$)?\n",
    "\n",
    "A \"unit\" increase in accelerationis **associated with** a ~1.191 \"unit\" increase in mpg.\n",
    "\n",
    "Meaning: An additional acceleration of 1 $m/s^2$ is **associated with** an increase ~1.191 miles per gallon.\n",
    "\n",
    "Keep in mind that this is not a statement of **causation**, but of **correlation**.\n",
    "\n",
    "What would the coefficient look like if an increase in acceleration was associated with a **decrease** in mpg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model for prediction\n",
    "\n",
    "Let's say that there was a new car model that had an acceleration of 28. What would we predict the mpg of that model to be?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 4.970 + 1.191 \\times 28$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:16:03.471319Z",
     "start_time": "2018-11-22T00:16:03.466887Z"
    }
   },
   "outputs": [],
   "source": [
    "# manually calculate it and confirm with the plot we created above. Does this value make sense?\n",
    "4.970 + 1.191*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:16:04.527165Z",
     "start_time": "2018-11-22T00:16:04.521798Z"
    }
   },
   "outputs": [],
   "source": [
    "type(acc_linreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:16:05.355294Z",
     "start_time": "2018-11-22T00:16:05.349891Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict for a new observation, here where the acceleration is 30\n",
    "acc_linreg.predict([[28], [30]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we would predict mpg of **~41** for a model with acceleration of 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Does the scale of the features matter?\n",
    "\n",
    "Let's say that acceleration was measured in centimeters per second squared, rather than meters per second squared. How would that affect the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Discussion\n",
    "\n",
    "Based on your intuition of Linear Regression so far: _should_ this matter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:16:55.434718Z",
     "start_time": "2018-11-22T00:16:55.414718Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['acceleration_centimeters'] = data.acceleration * 100\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:16:58.921443Z",
     "start_time": "2018-11-22T00:16:58.913474Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['acceleration_centimeters']\n",
    "X_2 = data[feature_cols]\n",
    "y = data.mpg\n",
    "\n",
    "# instantiate and fit\n",
    "acc_linreg2 = LinearRegression()\n",
    "acc_linreg2.fit(X_2, y)\n",
    "\n",
    "# print the coefficients\n",
    "print(acc_linreg2.intercept_)\n",
    "print(acc_linreg2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How do we interpret the new acceleration_centimeters coefficient ($\\beta_1$)?\n",
    "\n",
    "- A \"unit\" increase in acceleration is **associated with** a ~0.01191 \"unit\" increase in mpg.\n",
    "- Meaning: An centimeter/second^2 acceleration increase is **associated with** an increase in mpg of 0.01191.\n",
    "- Meaning: An additional 1 meter/second^2 acceleration increase is **associated with** an increase in mpg of ~1.191."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:00.270738Z",
     "start_time": "2018-11-22T00:17:00.265475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predict for a new observation\n",
    "acc_linreg2.predict(np.array([[3000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So what does this mean?\n",
    "\n",
    "**The scale of the features is irrelevant for linear regression models, since it will only affect the scale of the coefficients, and we simply change our _interpretation_ of the coefficients**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### How well does the model fit the data?\n",
    "\n",
    "R-squared is a very common way to evaluate the overall fit of a linear model.\n",
    "R-squared is defined as the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model. This value is between 0 and 1, where the higher the value is, the better the model is.\n",
    "\n",
    "We can get r-squared from our model by getting the pearson-r coefficient from a fancy jointplot and squaring it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:02.694205Z",
     "start_time": "2018-11-22T00:17:02.161293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot('acceleration', 'mpg',data, kind=\"reg\")\n",
    "print(\"R^2:\", stats.pearsonr(X.values.flatten(),y.values)[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm the R-squared value for our simple linear model using `scikit-learn's` prebuilt R-squared scorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:04.882127Z",
     "start_time": "2018-11-22T00:17:04.872861Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = acc_linreg.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:05.975809Z",
     "start_time": "2018-11-22T00:17:05.969895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(y[:5])\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:07.369707Z",
     "start_time": "2018-11-22T00:17:07.364608Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Two things to keep in mind when using R-squared:\n",
    "  * The threshold for a **\"good\" R-squared value** is highly dependent on the particular domain.\n",
    "  * R-squared is more useful as a tool for **comparing models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features, which is called **multiple linear regression**:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times acceleration + \\beta_2 \\times displacement + \\beta_3 \\times horsepower$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:16.916657Z",
     "start_time": "2018-11-22T00:17:16.886231Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create X and y except now with more columns in X\n",
    "mult_feature_cols = ['acceleration', 'displacement', 'horsepower']\n",
    "X_mult = data[mult_feature_cols]\n",
    "y_mult = data.mpg\n",
    "\n",
    "# instantiate and fit like last time\n",
    "multiple_linreg = LinearRegression()\n",
    "multiple_linreg.fit(X_mult, y_mult)\n",
    "\n",
    "coeffs = multiple_linreg.coef_\n",
    "intercept =  multiple_linreg.intercept_\n",
    "# print the coefficients like last time\n",
    "print(intercept)\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['horsepower'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:18.623445Z",
     "start_time": "2018-11-22T00:17:18.618760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pair the feature names with the coefficients\n",
    "dict(zip(mult_feature_cols, multiple_linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With this model we can interpret the coefficients as follows:\n",
    "\n",
    "  * For a fixed amount of displacement and horsepower, an increase of 1 m/s^2 in **acceleration** is associated with a **decrease in mpg of ~.40**.\n",
    "  * For a fixed amount of acceleration and horsepower, an increase of 1 in **displacement** is associated with an **decrease in mpg of ~.038**.\n",
    "  * For a fixed amount of acceleration and engine displacement, an increase of 1 unit in **horsepower** is associated with a **decrease in mpg of the car of ~.084**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Does this model have a better r^2 value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:26.285486Z",
     "start_time": "2018-11-22T00:17:26.280322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_mult_pred = multiple_linreg.predict(X_mult)\n",
    "metrics.r2_score(y_mult, y_mult_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise Time\n",
    "* Create the multiple regression when you use every continuous, numeric  variable except for mpg to predict mpg.\n",
    "* What is this new r^2 value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:28.172205Z",
     "start_time": "2018-11-22T00:17:28.158986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create X and y except now with more columns in X\n",
    "mult_feature_cols = ['acceleration', 'displacement', 'horsepower', 'cylinders', 'weight', 'year']\n",
    "X_mult = data[mult_feature_cols]\n",
    "y_mult = data.mpg\n",
    "\n",
    "# instantiate and fit like last time\n",
    "multiple_linreg_all = LinearRegression()\n",
    "multiple_linreg_all.fit(X_mult, y_mult)\n",
    "\n",
    "coeffs = multiple_linreg_all.coef_\n",
    "intercept =  multiple_linreg_all.intercept_\n",
    "# print the coefficients like last time\n",
    "print(intercept)\n",
    "print(coeffs)\n",
    "\n",
    "# pair the feature names with the coefficients\n",
    "print(dict(zip(mult_feature_cols, multiple_linreg_all.coef_)))\n",
    "\n",
    "y_mult_pred_all = multiple_linreg_all.predict(X_mult)\n",
    "metrics.r2_score(y_mult, y_mult_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's save our data to a `data` folder so we can load it in later:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation metrics for regression problems\n",
    "\n",
    "In order to evaluate how good a given regression model is, we need evaluation metrics designed for comparing **continuous values**. We will cover 3 common evaluation metrics for regression models here.\n",
    "\n",
    "Let's create some example numeric predictions, and calculate the three most common evaluation metrics for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:45.139455Z",
     "start_time": "2018-11-22T00:17:45.136720Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define true and predicted response values\n",
    "fake_y_true = [101, 40, 30, 20]\n",
    "fake_y_pred = [90, 50, 50, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors/residuals:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:46.402252Z",
     "start_time": "2018-11-22T00:17:46.399353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:47.127402Z",
     "start_time": "2018-11-22T00:17:47.122118Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"MAE for fake data:\", metrics.mean_absolute_error(fake_y_true, fake_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:48.007648Z",
     "start_time": "2018-11-22T00:17:48.003039Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"MSE for fake data:\", metrics.mean_squared_error(fake_y_true,fake_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.var(fake_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(fake_y_true, fake_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:49.234003Z",
     "start_time": "2018-11-22T00:17:49.228737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"RMSE for fake data:\",np.sqrt(metrics.mean_squared_error(fake_y_true, fake_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets compare these metrics in terms of their usefulness/interpretability:\n",
    "  * **MAE** is the easiest to understand, because it's the average error.\n",
    "  * **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "  * **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are what are called **loss functions**, because we want to minimize the **loss** (from getting stuff wrong)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise Time\n",
    "  * Calculate the MAE/MSE/RMSE of the simple linear regression model\n",
    "  * Calculate the MAE/MSE/RMSE of the 3 feature multiple regression model\n",
    "  * Calculate the MAE/MSE/RMSE of the model using all of the features\n",
    "  * What do you notice about all of these metrics as you keep adding features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:50.412990Z",
     "start_time": "2018-11-22T00:17:50.407980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y, y_pred))\n",
    "print(metrics.mean_absolute_error(y, y_mult_pred))\n",
    "print(metrics.mean_absolute_error(y, y_mult_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:51.224512Z",
     "start_time": "2018-11-22T00:17:51.211667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"MAE for SLR data:\", metrics.mean_absolute_error(y, y_pred))\n",
    "print(\"MSE for SLR data:\", metrics.mean_squared_error(y,y_pred))\n",
    "print(\"RMSE for SLR data:\", np.sqrt(metrics.mean_squared_error(y, y_pred)))\n",
    "\n",
    "print(\"MAE for MLR3 data:\", metrics.mean_absolute_error(y, y_mult_pred))\n",
    "print(\"MSE for MLR3 data:\", metrics.mean_squared_error(y, y_mult_pred))\n",
    "print(\"RMSE for MLR3 data:\",np.sqrt(metrics.mean_squared_error(y, y_mult_pred)))\n",
    "\n",
    "print(\"MAE for MLR data:\", metrics.mean_absolute_error(y, y_mult_pred_all))\n",
    "print(\"MSE for MLR data:\", metrics.mean_squared_error(y, y_mult_pred_all))\n",
    "print(\"RMSE for MLR data:\",np.sqrt(metrics.mean_squared_error(y, y_mult_pred_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using train/test split for model evaluation\n",
    "\n",
    "How do we know that our model will perform well on new data?\n",
    "\n",
    "Sure, we may know that our model has really low RMSE on all of the data we have on hand, but can we be sure that it will be exactly the same when we try to use our model in the real world?\n",
    "\n",
    "One way we can get an estimate of how the model will perform \"in the wild\" is by building the model on a portion of our data, and then testing it on the remainder that we have.\n",
    "\n",
    "So, we **act like we have one set of data for model building, and keep a separate set of data and treat it as if it were new.** We then test our model on this \"new\" data, and, **as long as the test data was taken in an unbiased way**, we can assume that the **loss** on the test data gives us a pretty good idea of what the error \"in the wild\" will be.\n",
    "\n",
    "So, let's try to use train/test split to estimate the model's accuracy on unseen data.\n",
    "\n",
    "The basic approach would be to randomly select a fraction of the data (>50% usually) for training, and the remainder (100-training%) for testing. We will use scikit-learn's `train_test_split` function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:52.493837Z",
     "start_time": "2018-11-22T00:17:52.485536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_mult_train, X_mult_test, y_mult_train, y_mult_test = train_test_split(X_mult, y_mult, \n",
    "                                                                        test_size=0.3, \n",
    "                                                                        random_state=71318)\n",
    "print(\"training data size:\", X_mult_train.shape)\n",
    "print(\"testing data size:\", X_mult_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we simply train on `X_mult_train` and `y_mult_train` and then generate predictions and evaluation metrics on `X_mult_test` and `y_mult_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:53.516577Z",
     "start_time": "2018-11-22T00:17:53.508456Z"
    }
   },
   "outputs": [],
   "source": [
    "#train on training set\n",
    "mult_linreg2 = LinearRegression()\n",
    "mult_linreg2.fit(X_mult_train, y_mult_train)\n",
    "\n",
    "#generate predictions on training set and evaluate\n",
    "y_mult_pred_train = mult_linreg2.predict(X_mult_train)\n",
    "print(\"Training set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_train, y_mult_pred_train)))\n",
    "\n",
    "#generate predictions on test set and evaluate\n",
    "y_mult_pred_test = mult_linreg2.predict(X_mult_test)\n",
    "print(\"Test set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_test, y_mult_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the test set error is greater than the training set error. This should always be the case (why?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time\n",
    "  * Get MAE/MSE/RMSE training and test set predictions on the full linear regression model (using all features) with a test set of 30% of the data\n",
    "  * Get MAE/MSE/RMSE training and test set predictions on the full linear regression model (using all features) with a test set of 20% of the data\n",
    "  * Get MAE/MSE/RMSE training and test set predictions on the full linear regression model (using all features) with a test set of 10% of the data\n",
    "  * Anything you notice about the test set error metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:54.645497Z",
     "start_time": "2018-11-22T00:17:54.635110Z"
    }
   },
   "outputs": [],
   "source": [
    "X_mult_train, X_mult_test, y_mult_train, y_mult_test = train_test_split(X_mult, y_mult, \n",
    "                                                                        test_size=0.3, \n",
    "                                                                        random_state=71318)\n",
    "print(\"training data size:\", X_mult_train.shape)\n",
    "print(\"testing data size:\", X_mult_test.shape)\n",
    "\n",
    "#train on training set\n",
    "mult_linreg2 = LinearRegression()\n",
    "mult_linreg2.fit(X_mult_train, y_mult_train)\n",
    "\n",
    "#generate predictions on training set and evaluate\n",
    "y_mult_pred_train = mult_linreg2.predict(X_mult_train)\n",
    "print(\"Training set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_train, y_mult_pred_train)))\n",
    "\n",
    "#generate predictions on test set and evaluate\n",
    "y_mult_pred_test = mult_linreg2.predict(X_mult_test)\n",
    "print(\"Test set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_test, y_mult_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:55.375465Z",
     "start_time": "2018-11-22T00:17:55.364579Z"
    }
   },
   "outputs": [],
   "source": [
    "X_mult_train, X_mult_test, y_mult_train, y_mult_test = train_test_split(X_mult, y_mult, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=71318)\n",
    "print(\"training data size:\", X_mult_train.shape)\n",
    "print(\"testing data size:\", X_mult_test.shape)\n",
    "\n",
    "#train on training set\n",
    "mult_linreg2 = LinearRegression()\n",
    "mult_linreg2.fit(X_mult_train, y_mult_train)\n",
    "\n",
    "#generate predictions on training set and evaluate\n",
    "y_mult_pred_train = mult_linreg2.predict(X_mult_train)\n",
    "print(\"Training set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_train, y_mult_pred_train)))\n",
    "\n",
    "#generate predictions on test set and evaluate\n",
    "y_mult_pred_test = mult_linreg2.predict(X_mult_test)\n",
    "print(\"Test set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_test, y_mult_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T00:17:55.957290Z",
     "start_time": "2018-11-22T00:17:55.945389Z"
    }
   },
   "outputs": [],
   "source": [
    "X_mult_train, X_mult_test, y_mult_train, y_mult_test = train_test_split(X_mult, y_mult, \n",
    "                                                                        test_size=0.1, \n",
    "                                                                        random_state=71318)\n",
    "print(\"training data size:\", X_mult_train.shape)\n",
    "print(\"testing data size:\", X_mult_test.shape)\n",
    "\n",
    "#train on training set\n",
    "mult_linreg2 = LinearRegression()\n",
    "mult_linreg2.fit(X_mult_train, y_mult_train)\n",
    "\n",
    "#generate predictions on training set and evaluate\n",
    "y_mult_pred_train = mult_linreg2.predict(X_mult_train)\n",
    "print(\"Training set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_train, y_mult_pred_train)))\n",
    "\n",
    "#generate predictions on test set and evaluate\n",
    "y_mult_pred_test = mult_linreg2.predict(X_mult_test)\n",
    "print(\"Test set RMSE:\", np.sqrt(metrics.mean_squared_error(y_mult_test, y_mult_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of linear regression and comparison with other models (you will see in the future)\n",
    "\n",
    "There are some obvious advantages to linear regression models:\n",
    "  * These kinds of models are very simple to explain\n",
    "  * They are highly interpretable\n",
    "  * Model training and prediction is very fast\n",
    "  * Features do not need to be scaled (we will talk about feature scaling later)\n",
    "  * They can perform well with a small number of observations\n",
    "\n",
    "However, linear regression also has some significant disadvantages:\n",
    "  * It assumes a linear relationship between the features and the outcome. This isn't always (almost never) the case.\n",
    "  * Performance is (generally) not competitive with the best supervised learning methods\n",
    "  * When you have lots of features, this approach can become sensitive to useless features\n",
    "  * This approach can't automatically learn feature interactions (although you can code them into a linear regression, will show you how to do that soon!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
