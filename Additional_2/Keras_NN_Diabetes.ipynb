{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "# url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "# names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "#          \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv')#, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>12</td>\n",
       "      <td>106</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.137</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.362</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.597</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.962</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.446</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "333           12      106             80              0        0  23.6   \n",
       "625            4       90             88             47       54  37.7   \n",
       "136            0      100             70             26       50  30.8   \n",
       "57             0      100             88             60      110  46.8   \n",
       "241            4       91             70             32       88  33.1   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "333                     0.137   44        0  \n",
       "625                     0.362   29        0  \n",
       "136                     0.597   21        0  \n",
       "57                      0.962   31        0  \n",
       "241                     0.446   22        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"Outcome\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.823\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeZyO9f7H8dfXvisqspclSQuRFpUjKZw4rQeVOqdOnXNaLGHsWzJSESd1dJQOfopKIqMkBokQsq9DtuxmjDFjtu/vj/vmTNPgHnPf872X9/PxmIf7uu/rvu73XHO5P/fnur7XdRtrLSIiIhI8CrgOICIiIr+l4iwiIhJkVJxFRESCjIqziIhIkFFxFhERCTIqziIiIkFGxVkikjGmuDFmljEmwRjzqes8kcQY87Qx5vss0yeNMVf78LwaxhhrjCkU2IRuGWN2GWNanOOxZsaYvfmdSfKfinME8P5nT/a+CR4wxnxkjCmVbZ7bjTHzjTGJ3oI1yxhTL9s8ZYwxbxtjdnuXtcM7fdk5XtcYY142xqw3xiQZY/YaYz41xlwfyN/XR48AFYDy1tpH87ow75tmpne9JBpjthhj/pJtHutdDye9P/F5fV0fcn1kjEn1vt4xY8y3xpi63scGGWMmZ8t3KGvxM8YU9t73uwsieJedboy5Mi8ZrbWlrLVxeVnGhURKYZfwoeIcOR6w1pYCbgIaAL3PPGCMuQ2YC3wJVAKuAn4GlpzpaIwxRYDvgOuA+4EywG3AUeCWc7zmaKAz8DJQDqgDzADa5DZ8AN5UqwNbrbXpfsyy37uOywBdgf8YY67JNs+N3mJUylp7SW5f+yKN8OaqAhwCPjrPvMeBVlmmW3nv+w1jTEngYSABeMJvScOcPhyIr1ScI4y19gDwDZ4ifcYIYKK1drS1NtFae8xa2w9YBgzyztMJqAY8aK3daK3NtNYesta+aq2Nyf46xpjawAtAB2vtfGvtaWvtKWvt/1lrh3vniTXGPJvlOdl3d1pjzAvGmG3ANmPMe8aYN7O9zpfGmG7e25WMMZ8bYw4bY3YaY17OaR0YYwYDA4A/ezvKZ4wxBYwx/Ywxv3g7xYnGmLLe+c90Xc8YY3YD8y+wjq13nRwDbjjfvOfI50uWp7x7MI4YY/r6slxr7SlgClD/PLNNwvO3PqMTMDGH+R4G4oEhwFMX+H3KG2NmGmNOGGOWAzWzPW6NMbW8t9sYY1Z7591jjBmUwyL/aozZb4z51RjTPctyChhjenn36Bw1xkwzxpTzPrzI+2+8929+m/c5fzXGbDLGHDfGfGOMqe693xhjRnnX/wljzDpjTI7rzbsdRxtjlnvn/fLM655r2zHGtDXGbDDGxHuff222xTY2xmz05ppgjCl2jtc+5zbv3TPyqTFmsvHszVlnjKljjOnt/b32GGNa5rRccU/FOcIYY6rg6Ya2e6dLALcDOR13nQbc673dAvjaWnvSx5e6B9hrrV2et8T8CWgC1AM+xlNQDYAx5lKgJfCJMaYAMAtPx1/Z+/pdjDH3ZV+gtXYgMAyY6u1gPwCe9v78AbgaKAW8k+2pdwPXAr9bZlbeItEWuAzves4lX7I0Ba7B83sOyOHNPadcpYDHgdXnmW0GcJcx5hLv+r0Tzx6V7J7C8/f4BKhrjLn5PMscC6QAVwJ/9f6cSxKeDwSX4NnD8g9jzJ+yzfMHoDaev32U+d/x2ZfwbC9349kDdNz72gB3ef+9xPs3X2qMaQf0AR4CLgcWe38nvMu+C8/enrLAY3j2Ep1LJ+/vdSWQDozJ9vjZbccYU8f7Ol28rxsDzDKevVNnPI5nO6vpzdAv+wv6uM0/gOcD16V4/u7f4Hnfr4zng9W48/xO4pK1Vj9h/gPsAk4CiYDFs3v6Eu9jVbz31c3hefcDad7b3wLDc/GafYFlF5gnFng2y/TTwPdZpi3QPMu0AXYDd3mn/wbM995uAuzOtvzewIRzvPYgYHKW6e+Af2aZvgZIAwoBNbxZrj7P79IMyMTTTZ4GMoAu2eaxwAnvPPHAmHMsy5csVbI8vhxof45lfYSnMMYDB4CZQM1zrAML1ALGA88Dfwf+473PZpmvmvd3vck7/Q0w+hyvX9CbvW6W+4bl8HeudY7nvw2M8t4+87tnXdYI4APv7U3APVkeuzKH9VYoy+NzgGeyTBcATuE55NEc2ArcChTwYTsenmW6HpDq/d1/t+0A/YFp2V53H9Asy//Xv2d5vDWwI8t2tteXbd779/02y2MP4HkfKOidLu3Ndomv/6/1k38/6pwjx5+staXx/Oeui6erA093kYnnjSy7K4Ej3ttHzzHPueR2/nPZc+aG9byjfAJ08N7VEfg/7+3qQCXvbsJ44xls1QfPoC9fVAJ+yTL9C5439azP38P57bee48hl8HROzXOYp6G19hLvT4673X3MciDL7VN4uutzedP7ehWttW2ttTsu8HtMxNMJnmuX9pPAJmvtGu/0/wEdjTGFc5j3cm/2rOvulxzmA8AY08QYs8C7mzYBzweE7AMOsy+rkvd2deCLLH//TXg+JJ1rG6gOjM4y/zE8HwArW2vn49lbMRY4ZIx53xhT5ly5c8hUOFvurI//5u9rrc30Pl7Zh98xe/4LbfMHs9xOBo5YazOyTMP5tx1xRMU5wlhrF+Lppt70TicBS4GcRiw/hqeLA5iHZ5dcSR9f6jugijGm0XnmSQJKZJmumFPkbNMfA494jw02AT733r8H2Jml8F1irS1trW3tY979eN7szqiGZ/dk1jc3n77CzVp7GogCrs9hl6y/sgTSYjwfrCoA3+fweCfgauMZ+X8AGImnEOW0rg/jyV41y33VzvPaU/B091WttWWBf+MpmFllX9Z+7+09QKts20Axa+0+cv7b7QGezzZ/cWvtDwDW2jHW2pvxdMJ1gB7nyZ09Uxr/+2BLttf/zd/Xe5imKp7u+UK/Y/b8ednmJYipOEemt4F7jTE3eqd7AU8Zz2lPpY0xlxpjhuIZjT3YO88kPG8Gnxtj6nqPq5Y3xvQxxvzuzcBauw14F/jYeE4zKmKMKWaMaW+M6eWdbQ3wkDGmhHdA0DMXCm6tXY3nTW888I219szpSMuBRGNMlPGcw1zQGFPfGNPYx3XyMdDVGHOV99jsmWPSuR7N7c2ZCryFZ+BZbvk1S25591A8ALT13j7LO5CqJp4R+jd5f+rjKaqdsi0Kb5c2HRjk/TvX4/wDyEoDx6y1KcaYW/DsHcmuv3dZ1wF/AaZ67/838FqWQV2Xe48rg+dDQiaeY/hkmb+3dzkYY8oaYx713m7s7eIL4/kQmeJ9/rk8YYyp5x3DMQT4LEuHmt00oI0x5h7v8l/BcyjkhyzzvGCMqeIdWNY3y++YVV63eQliKs4RyFp7GM/uygHe6e/xDD55CPgVz260BkBTb5E90w22ADbjOf58As+bw2XAj+d4qZf5367BeGAH8CCeQSwAo/AcmzsI/Jf/7aK+kCneLFOy/E4ZwB/xFIud/K+Al/VxmR/i+QCyyPv8FDwDjPLiQ6CaMeaBi3iev7PkirV2g7V2Qw4PPQV8aa1dZ609cOYHz2lzfzT/Gx2d1Yt4dp0ewLPXZsJ5XvqfwBBjTCKe7XNaDvMsxDPQ7js8u+zneu8fjafrnut9/jI8e1ewnpHqr+E5PTDeGHOrtfYL4HU8AwpPAOv532lkZfAcbz+O5//DUeCN8+Se5P3dDgDF8Gz7ObLWbsFz+tm/8GynD+A51TE1y2xT8JzeGIfn/83QHJaT121egpjJ9sFYRERywRgTi2dg3XjXWSR8qHMWEREJMirOIiIiQUa7tUVERIKMOmcREZEgo+IsIiISZC74DSnGmA/xDNc/ZK393YXfvSfQj8ZzAYJTwNPW2lUXWu5ll11ma9SocXY6KSmJkiV9vb6F5JbWb2Bp/QaO1m1gaf0GTvZ1+9NPPx2x1l7uy3N9+fqyj/Ccq5rTZfzAc15gbe9PE+A977/nVaNGDVauXHl2OjY2lmbNmvkQRy6G1m9gaf0GjtZtYGn9Bk72dWuMOeela7O74G5ta+0iPNecPZd2eL5u0FprlwGXmDx++bqIiEgk88cXf1fmtxdp3+u971c/LFtERILEmjVrmDRpEunp+XIl2ZCXlJR00Xsl/FGcfWaMeQ54DqBChQrExsaefezkyZO/mRb/0voNLK3fwNG6DSxf1m98fDwffPABs2fPplChQhQtWjR/woUoay2pqalUqVLlorddfxTnffz2G1Sq8NtvVznLWvs+8D5Ao0aNbNZPFDruEVhav4Gl9Rs4WreBdb71m5qaytixYxk8eDBJSUl06dKFAQMGcMkll+RvyBCSmZnJpk2bKFKkCPv27bvobdcfp1LNBDoZj1uBBGutdmmLiISwr7/+mhtuuIFu3bpx2223sW7dOkaOHKnCfB7WWnr37o21ltq1a+dpWb6cSvUx0Ay4zBizFxiI54vEsdb+G4jBcxrVdjynUv0lT4lERMSZrVu30q1bN2bPnk3t2rX56quvaN26NZ6zZuVc0tLSWLJkCb169eLSSy/N8/IuWJyttR0u8LgFXshzEhERcSYhIYFXX32VMWPGULx4cd58801eeuklihQp4jpaSHj11Vfp1KmTXwoz5POAMBERCYyMjAxmzJhBfHx8rp63efNmli9fzltvvcXhw4d55plnGDp0KBUqVAhQ0vBy+vRpPv/8cwYOHEjBggX9tlwVZxGRMPD666/Tt2/fi37+HXfcQUxMDDfffLMfU4W/d999l4cfftivhRlUnEVEQt7+/fsZNmwYbdu25Z133snVc5cuXUrTpk258sordVw5F5KSkhg3bhzdunULyPJVnEVEQlzv3r1JS0tj5MiRVK1a9cJPyGLHjh1UqlQpQMnC14wZM+jYsWPAlq9vpRIRCWHLly9n4sSJdO3alZo1a7qOE/YSEhKIioqiY8eOVKxYMWCvo+IsIhKirLV07tyZihUr5ul4s/gmNTWV5cuXExUVFfBDANqtLSIRYevWrSQkJLiO4Vfff/89y5YtY8KECZQuXdp1nLB25MgRBg4cyKhRo/Ll9DIVZxEJe1u3buWaa65xHSMgGjduTKdOnVzHCGtHjx7ll19+ITo6Ot/O+1ZxFpGwd6ZjHjBgALfccovjNP511113UaCAjlAGyq+//srQoUMZMWIEJUuWzLfXVXEWkYhxyy230KZNG9cxJETs3buX48eP88Ybb1CiRIl8fW193BIREcnm119/ZcSIEdSuXTvfCzOocxYREfmNHTt2kJiYyBtvvOHsu6tVnEXkd06fPo3nO23cS01NJSUlJU/LOH36tJ/SSLg7ceIE7733HtHR0RQuXNhZDhVnEfmN4cOH07t3b9cxAqJQIb3lyblt3LiRgwcP8sYbbzi/lKm2VBH5jW+++Yarr76av/3tb66jABAXF8fVV1+d5+WULFmSu+++2w+JJBylp6fz+eef06dPH+eFGVScRSQLay1r1qyhffv29OrVy3UcAGJjY2nWrJnrGBLGVq1aRVxcHP3793cd5SyN1haRs3bt2kV8fDwNGjRwHUUkX1hrWbFiBQ8//LDrKL+hzllEzlq1ahWAirNEhCVLlrB+/Xqef/5511F+R52ziJy1evVqChYsyPXXX+86ikhAJSUlcfz4cZ577jnXUXKkzllEzlq9ejXXXnstxYoVcx1FJGDmzZvHhg0b6Ny5s+so56TOWUTOWr16tXZpS1jbuXMn5cuXD+rCDCrOIuJ18OBBfv31Vxo2bOg6ikhAfPXVV8yZMyckPoBqt7aIAJ6uGTQYTMLT999/T+PGjfnjH//oOopP1DmLCPC/4nzTTTc5TiLiXzExMWzfvp0KFSq4juIzdc4iAniK89VXX03ZsmVdRxHxm+nTp9OyZUtKlSrlOkquqHMWEUCDwST8LFq0iNTU1JArzKDiLCJAQkIC27dvV3GWsPHBBx9Qv3592rdv7zrKRVFxFhF+/vlnQIPBJDysX7+eyy67jHLlyrmOctFUnEXk7GAwnUYloW706NGUKFGCdu3auY6SJyrOIsLq1aupWLEiFStWdB1F5KLt2bOHevXq+eUrRl1TcRYRDQaTkGatZfjw4Rw5coR7773XdRy/UHEWiXCnTp1i48aNKs4Skqy17N27lz/84Q9htQ2rOItEsOPHj9OmTRvS09O55557XMcRyRVrLYMHD+bAgQM0adLEdRy/0kVIRCLUzp07ad26NXFxcUyePJnmzZu7jiTis8zMTDZs2MATTzxBrVq1XMfxO3XOIhFo+fLl3HrrrRw8eJC5c+fy+OOPu44k4jNrLf369SMzMzMsCzOocxaJOF9++SUdOnSgYsWKxMTEULduXdeRRHyWnp5ObGwsUVFRYX2pWXXOIhFkzJgxPPjgg1x//fUsW7ZMhVlCzrBhw6hatWpYF2ZQ5ywSETIyMnjllVcYPXo0Dz74IJMnT6ZEiRKuY4n4LDU1lalTp9KvXz8KFAj/vjL8f0ORCHfq1CkeeeQRRo8eTZcuXfj0009VmCXk/Oc//+HOO++MiMIM6pxFwtrBgwd54IEHWLlyJaNHj+bll192HUkkV5KTk3nnnXfo0aOH6yj5SsVZJExt2rSJ1q1bc/DgQb744ouQv9awRB5rLbNmzYrIswkiY/+ASISJjY3l9ttvJzk5mYULF6owS8hJTEykR48ePPLII1SqVMl1nHyn4iwSZiZPnkzLli258sorWbZsGY0bN3YdSSRXUlJS+Omnn+jVq1fEHGPOTru1RULM7t27SU9Pz/GxyZMnM3DgQJo1a8b06dO59NJL8zmdSN4cO3aMfv36MXLkSIoVK+Y6jjMqziIhZODAgQwZMuS88zz55JOMHz+eIkWK5FMqEf84evQou3fvJjo6OqILM6g4i4SMbdu2ER0dTdu2bXn44YdznKd8+fK0bt0aY0w+pxPJm4MHDzJkyBCGDx9O6dKlXcdxTsVZJER0796dokWLMm7cOCpWrOg6jojf7N+/nyNHjjBixAhKlizpOk5QiMwj7SIhZt68ecycOZN+/fqpMEtYOXz4MMOHD6d27doqzFmocxYJcunp6XTp0oWrr76aLl26uI4j4je7du3i6NGjvPHGGxQtWtR1nKCizlkkyI0bN44NGzbw5ptv6g1MwsapU6f417/+xfXXX6/tOgfqnEUc6Ny5M+PHj/dp3pSUFJo3b86f/vSnAKcSyR9btmxh165dvPnmmxq8eA4qziL5bOHChYwZM4YHHniAa6655oLzFylShH/+8596E5OwkJGRwWeffUZUVJS26fNQcRbJRxkZGXTp0oVq1aoxdepUihcv7jqSSL75+eefWb9+PX379nUdJeipOIvkow8//JA1a9aoMEvEyczMZMWKFfz1r391HSUkqDiL5JOEhAT69u3LnXfeyaOPPuo6jki+WbZsGStWrOCll15yHSVkaLS2SD559dVXOXLkCG+//baOtUnESExM5Pjx47z44ouuo4QUdc4iATJ06FBmz559dnrlypX89a9/pWHDhg5TieSf2NhYVq5cSffu3V1HCTnqnEUCZMqUKcTFxVGmTBnKlCnDY489RnR0tOtYIvli+/btlCtXToX5IqlzFgmgu+++m2nTprmOIZKvvv76a7Zu3crLL7/sOkrIUnEWERG/WbRoEQ0bNuT+++93HSWkabe2iIj4xdy5c9myZQtXXHGF6yghT52ziIjk2fTp02nRogUtW7Z0HSUsqHMWCQBrLWlpaa5jiOSLH3/8keTkZMqUKeM6SthQcRbxs7S0NJ599lm2b9/OTTfd5DqOSEBNmDCBGjVq8Pjjj7uOEla0W1vEjxISEnjkkUeYN28eAwYMoHfv3q4jiQTMtm3bKFOmDBUqVHAdJeyocxbxkz179nDnnXcSGxvLhAkTGDx4sK4EJmFr7NixZGRk8PDDD7uOEpbUOYv4wbZt2+jYsSNJSUl8/fXX3HPPPa4jiQTMgQMHqFWrFnXr1nUdJWypcxbJo5iYGF5++WUKFy7MkiVLVJglbFlrefPNN9m9ezf33Xef6zhhTZ2zRDxrLR9//DHHjx/P9XP379/P8OHDqVmzJgsXLuTKK68MQEIR96y17Nu3j6ZNm3LLLbe4jhP2VJwl4m3atClPI00feOAB/vGPf6gwS9iy1jJ06FBatGjBbbfd5jpORFBxloh35nzkCRMm0KZNm1w9t0CBApQrV46FCxcGIpqIc9Za1q1bR8eOHalZs6brOBFDxVnEq2zZslx++eWuY4gElUGDBtGuXTsV5nym4iwiIr+TkZHBvHnz6N69O6VLl3YdJ+JotLaIiPzOiBEjqFq1qgqzI+qcJSIdO3aMDRs2AJ4vhRcRj7S0NCZPnkxUVBQFCqh/c0XFWSLSX/7yF2bOnPmb+0qVKuUojUjw+Oijj2jevLkKs2MqzhKREhMTqV+/Pm+//TYAxYsX59Zbb3WcSsSdlJQU3nrrLfr06aPLzgYBn4qzMeZ+YDRQEBhvrR2e7fFqwH+BS7zz9LLWxvg5q4hfXXrppbqalwie06XmzJnDU089pcIcJC6438IYUxAYC7QC6gEdjDH1ss3WD5hmrW0AtAfe9XdQERHxv+TkZLp168YDDzxAlSpVXMcRL18OKtwCbLfWxllrU4FPgHbZ5rHAmW/ZLgvs919EEREJhOTkZLZv307v3r0pVEhHOYOJL3+NysCeLNN7gSbZ5hkEzDXGvASUBFrktCBjzHPAcwAVKlQgNjb27GMnT578zbT4V7iu3/T0dFJSUnL9vKNHjwL4bZ2E6/oNBlq3gXHy5En+85//8MQTT7Bx40Y2btzoOlLYycu266+PSh2Aj6y1bxljbgMmGWPqW2szs85krX0feB+gUaNGtlmzZmcfi42NJeu0+Fc4rt/jx4/TqFEj4uLiLur5zZs399s6Ccf1Gyy0bv3v2LFj7Nmzh48++oiff/5Z6zdA8rLt+lKc9wFVs0xX8d6X1TPA/QDW2qXGmGLAZcChi0ol4oMhQ4awc+dOhg4dSokSJXL9fL0hSSQ6cuQIAwcOZNiwYZQtW9Z1HDkHX4rzCqC2MeYqPEW5PdAx2zy7gXuAj4wx1wLFgMP+DCqS1ebNm3nnnXd49tln6du3r+s4IiHhwIEDHDx4kOHDh+vKX0HuggPCrLXpwIvAN8AmPKOyNxhjhhhj2npnewX4mzHmZ+Bj4GlrrQ1UaJFu3bpRokQJhg4d6jqKSEg4fvw4r776KrVq1VJhDgE+HXP2nrMck+2+AVlubwTu8G80kZzFxMQwZ84c3nrrLa644grXcUSC3u7du9m/fz8jR46kaNGiruOID3R9NgkpaWlpdOvWjTp16vDiiy+6jiMS9E6fPs3o0aNp0KCBCnMI0Ylt4tz+/ftp2bIlJ06cuOC8qampHDx4kK+++ooiRYrkQzqR0LVt2za2bNnCm2++qSt/hRgVZ3Fu+vTpbNiwgccff9yngnvjjTfSunXrfEgmErqstXz22Wf06NFDhTkEqTiLc3PmzKFWrVpMnjzZdRSRsLB+/XpWrlxJ7969XUeRi6RjzuJUcnIy8+fPVycs4ieZmZmsXLmSTp06uY4ieaDOWZyKjY0lJSVFxVnED1auXMmiRYvo1q2b6yiSR+qcxak5c+ZQvHhx7r77btdRREJaQkICx44do2vXrq6jiB+oOIsz1lpmz55N8+bNKVasmOs4IiFr8eLFvPfee7Rs2VKDv8KEirM4s23bNuLi4rRLWyQPtmzZQrly5YiKinIdRfxIxVmciYnxXHSuVatWjpOIhKZ58+Yxe/ZsrrvuOnXMYUYDwsSZOXPmULduXa666irXUURCzqJFi7jhhhto0aKF6ygSAOqcxYmkpCRiY2O1S1vkIsTGxrJx40ZdWz6MqXMWJ+bPn09qaqqKs0guffHFFzRr1kzfRx7mVJzFb3bs2MF///tf0tPTLzjvwoULKVWqFE2bNs2HZCLhYc2aNZw4cYJLL73UdRQJMBVn8YslS5bQrl07jh07RqFCvm1WzzzzjL4lR8RHkyZNolmzZjz11FOuo0g+UHGWPJs2bRqdOnWiWrVq/Pjjj9SsWdN1JJGwsnv3booWLUrVqlVdR5F8ogFhctGstYwYMYI///nPNG7cmKVLl6owi/jZuHHjOH78OI899pjrKJKPVJzloqSnp/PPf/6TqKgo/vznP/Ptt99Svnx517FEwsrhw4epVq0aN954o+soks9UnCXXEhMTadu2Lf/+97/p1asXU6ZM0eU3Rfxs1KhRbNmyRRfpiVA65iy5cuDAAVq1asW6desYN24czz33nOtIImHFWsu+ffu4/fbbadKkies44og6Z8mVf/3rX6xdu5ZZs2apMIv4mbWW6Ohodu7cqcIc4dQ5S64kJydTsmRJ7WoT8TNrLWvWrKFDhw66pK2ocxYRCQZDhw4lPT1dhVkAdc4iIk5lZmYSExNDt27dKFmypOs4EiTUOYuIODRy5EiqV6+uwiy/oc5ZRMSB9PR0JkyYwCuvvKLvYpbfUecsubJnzx6KFCniOoZIyJs8eTJ33323CrPkSMVZfLZixQo+++wznn32WddRRELW6dOnGTJkCE899RR16tRxHUeClIqz+MRaS+fOnalQoQJ9+/Z1HUckJFlrmTdvHk899ZQ6ZjkvFWfxyccff8zSpUsZNmwYpUuXdh1HJOScOnWKrl27cu+991K9enXXcSTIqTjLBSUlJREVFcXNN9/M008/7TqOSMhJTk5m3bp19OrVS2M2xCcqznJBI0aMYO/evbz99tsUKKBNRiQ3Tpw4Qffu3albty4VK1Z0HUdChE6lkvNKTEw8+53NTZs2dR1HJKQcP36c3bt3M2TIEMqWLes6joQQtUFyXvHx8aSkpHDvvfe6jiISUo4dO0a/fv2oXr26vutcck2ds4iInx0+fJh9+/YRHR1NmTJlXMeREKTOWUTEjxITExk8eDC1atVSYZaLps5ZRMRP9u3bx86dOxk5cqRGZUueqHMWEfGD9PR0Ro8eTaNGjVSYJc/UOYuI5FFcXBw///wzI0aMcB1FwoQ6ZxGRPLDW8vnnn/PHP/7RdRQJI+qcRUQu0qZNm1i8eDE9evRwHUXCjDpnEU45dxMAACAASURBVJGLkJGRwU8//cQzzzzjOoqEIXXOIiK5tHr1aubOnUtUVJTrKBKm1DmLiOTC8ePHOX78uHZlS0CpOIuI+OiHH35g7NixNG/eXF8CIwGlrUtExAebNm3i0ksvpW/fvq6jSARQcRYRuYCFCxfy1VdfUbduXYwxruNIBNCAMBGR81i4cCF169bl7rvvdh1FIog6ZxGRc/jhhx9Yt24dFSpUcB1FIow6ZxGRHHz55Zfcfvvt3H777a6jSARScQ5j3333HWvWrAFgx44d/PTTT7leRnx8vL9jiQS9jRs3cuTIES6//HLXUSRCqTiHsaeffpq9e/fmeTkFChSgWrVqfkgkEvz+7//+j1tvvVVX/hKnVJzDWHp6Ok8//TRjxoxh8eLF3HnnnRe1nIIFC1KiRAk/pxMJPgcOHKBAgQLUrFnTdRSJcCrOYa5IkSKULl2aEiVKULp0addxRILW+PHjufHGG+nQoYPrKCIarS0icuzYMa688koaN27sOooIoM5ZRCLcmDFjuP7662nTpo3rKCJnqTiLSMTau3cvTZo0oUmTJq6jiPyGdmuLSEQaPnw427ZtU2GWoKTOWUQiirWWn376iY4dO+oUQQla6pxFJKK8/vrrpKWlqTBLUFPnLCIRITMzk1mzZtG5c2eKFy/uOo7IealzFpGIMHbsWKpXr67CLCFBnbOIhLWMjAz+85//8OKLL+q7mCVkqHMOU0lJSZw8eZJChfT5SyLb1KlTadasmQqzhBS9c4ep119/nZMnT9KxY0fXUUScSE1NZdiwYQwYMIACBdSHSGjRFhuGfvnlF9544w3at2/PHXfc4TqOSL7LzMxk4cKFPPXUUyrMEpK01YahqKgojDG8/vrrrqOI5Lvk5GS6du1K06ZNueqqq1zHEbkoKs5hZvHixUydOpWePXvqPE6JOKdOnWLjxo307NlTo7IlpKk4h5HMzEy6dOlClSpV6Nmzp+s4IvkqMTGRHj16UKNGDSpXruw6jkieaEBYEIqOjubtt9/O9fMyMjI4evQoU6ZMoUSJEgFIJhKcEhIS2LVrF4MGDaJ8+fKu44jkmYpzEFq6dCkZGRk8+uijuX5unTp1aN++fQBSiQSn+Ph4+vTpw9ChQylXrpzrOCJ+oeIcpKpVq8Z7773nOoZIUDty5Ai7d+8mOjqasmXLuo4j4jc65iwiISk5OZlBgwZRu3ZtFWYJO+qcRSTk/Prrr2zatIlRo0ZRuHBh13FE/E6ds4iElMzMTN5++21uvfVWFWYJW+qcg8ChQ4d49tlnOXXqFABr1qzROcoiOdi1axfLli3TBXYk7PnUORtj7jfGbDHGbDfG9DrHPI8ZYzYaYzYYY6b4N2Z4mzp1KrNmzeLUqVOkpKRQt25dXRNbJAfTp0/noYcech1DJOAu2DkbYwoCY4F7gb3ACmPMTGvtxizz1AZ6A3dYa48bY64IVOBwNGfOHGrXrs0PP/zgOopIUNqyZQvffvst3bp1cx1FJF/40jnfAmy31sZZa1OBT4B22eb5GzDWWnscwFp7yL8xw9epU6dYsGABrVu3dh1FJChlZGSwatUq/v73v7uOIpJvfCnOlYE9Wab3eu/Lqg5QxxizxBizzBhzv78ChrvY2FhSUlJUnEVysHbtWqZMmUKHDh303eQSUfy1tRcCagPNgCrAImPM9dba+KwzGWOeA54DqFChArGxsWcfO3ny5G+mI8X48eMpVqwYQEB//0hdv/lF69f/EhIS2LlzJ+3atdO6DSBtu4GTl3XrS3HeB1TNMl3Fe19We4EfrbVpwE5jzFY8xXpF1pmste8D7wM0atTINmvW7OxjsbGxZJ2OBNZannnmGVq0aEHLli0D+lqRuH7zk9avfy1fvpwFCxYwePBgrdsA0/oNnLysW192a68AahtjrjLGFAHaAzOzzTMDT9eMMeYyPLu54y4qUQTZunUrcXFx2qUtksWGDRsoW7YsgwYNch1FxJkLFmdrbTrwIvANsAmYZq3dYIwZYoxp653tG+CoMWYjsADoYa09GqjQ4SImJgaAVq1aOU4iEhyWLFnCzJkzqVOnDsYY13FEnPHpmLO1NgaIyXbfgCy3LdDN+yM+mjNnDtdeey01atRwHUXEuUWLFlGnTh1uv/12FWaJeLp8pyMnT55k4cKF2qUtAqxcuZJVq1ZRsWJFFWYRVJydmT9/PqmpqSrOEvFmzZpFpUqV6NKli+soIkFDJw7mk+TkZGbMmMHp06cBmDZtGqVKlaJp06aOk4m4s2PHDn799VcqVarkOopIUFFxziczZ8783fWyO3ToQJEiRRwlEnFr6tSpXH/99Tz33HOuo4gEHRXnfHKmY164cOHZb5yqXDn7hdZEIsPRo0dJT0+nXr16rqOIBCUV53xWpUoVjc6WiPbRRx9Rq1YtHn/8cddRRIKWBoSJSL5JSEjg8ssv11gLkQtQ5ywi+eLdd9+lVq1atGnTxnUUkaCn4iwiAbdnzx4aN25M48aNXUcRCQnarS0iAfXWW2+xefNmFWaRXFDnLCIBYa1l+fLltG/fXmcmiOSSOmcRCYiRI0eSnp6uwixyEdQ5i4hfWWv54osveOGFFyhWrJjrOCIhSZ2ziPjV+++/T/Xq1VWYRfJAnbOI+EVGRgbvvvsuL774or5ZSiSP1DmLiF9Mnz6d5s2bqzCL+IGKs4jkSVpaGv379+fBBx/kuuuucx1HJCyoOIvIRcvMzGTJkiU89dRTFCqko2Qi/qLiLCIXJSUlha5du3LzzTdTq1Yt13FEwoo+6opIriUnJ7Nlyxa6d+9O6dKlXccRCTvqnEUkV5KSkujRoweVKlWiatWqruOIhCV1ziLis8TERHbu3En//v254oorXMcRCVvqnEXEJ4mJifTq1YtKlSpRoUIF13FEwpo6ZxG5oGPHjhEXF8ewYcMoW7as6zgiYU+ds4icV2pqKgMGDKB27doqzCL5RJ2ziJzTwYMHWbNmDW+//bbOYxbJR+qcRSRH1lrGjBlD06ZNVZhF8pn+x4nI7+zZs4fY2Fhee+0111FEIpI6ZxH5nRkzZvDoo4+6jiESsdQ5i8hZO3bsYObMmXTt2tV1FJGIps5ZRADPt0utWrWKF1980XUUkYinzllE2LBhA9OmTWPw4MGuo4gI6pxFIt6hQ4eIj49nwIABrqOIiJc6Zz/at28fEydOJDMz83ePrV692kEikfP76aef+OKLL3j11VcxxriOIyJeKs5+9Nprr/Hee++d8/Fy5cpRvnz5fEwkcm7r16+ndOnSKswiQUi7tf3EWktMTAwPPPAAqampOf4cOnRIlz+UoLB8+XJmzJhB7dq1VZhFgpCKs59s3ryZX375hTZt2lC4cOEcfwoWLOg6pgiLFy+mSpUq9O3bV4VZJEipOPtJTEwMAK1atXKcROTc1q5dy/Lly6lUqZIKs0gQU3H2k5iYGOrXr0+1atVcRxHJUUxMDGXLluWVV15xHUVELkDF2Q8SExNZvHgxrVu3dh1FJEd79uxh165dVK9e3XUUEfGBirMffPfdd6SlpWmXtgSlzz77jKNHj/LPf/7TdRQR8ZGKsx/ExMRQunRp7rjjDtdRRH4jISGB5ORkbrrpJtdRRCQXdJ5zHp05haply5YULlzYdRyRsyZNmkTlypV58sknXUcRkVxS55xH69evZ9++fdqlLUHlxIkTlC9fnubNm7uOIiIXQZ1zHukUKgk248aNo0qVKrRp08Z1FBG5SCrOuWStZc+ePVhrAZg5cyY33XQTlSpVcpxMBH755RcaNWrEzTff7DqKiOSBdmvn0nPPPUf16tWpUaMGNWrU4IcfftApVBIURo8ezcaNG1WYRcKAOudc+OGHHxg/fjydOnWiWbNmABQsWJB27dq5DSYRzVrLDz/8wGOPPcaVV17pOo6I+IGKs48yMzPp3LkzlSpVYuzYsZQqVcp1JBEAxowZw0033aTCLBJGVJx9NGnSJFauXMmkSZNUmCUoWGv59NNP+fvf/07RokVdxxERP9IxZx8kJibSq1cvmjRpQseOHV3HEQFgwoQJVK9eXYVZJAypc/ZBdHQ0Bw4cYMaMGRQooM8z4lZmZiZjxoyhc+fO+mYpkTClSnMBcXFxvPXWWzz55JM0adLEdRwRvvrqK5o3b67CLBLGVJwvoEePHhQuXJjo6GjXUSTCpaen079/f+677z5uuOEG13FEJIBUnM9jwYIFTJ8+nd69e1O5cmXXcSSCZWRksHz5cp588kkdYxaJACrO55CRkUGXLl2oXr063bp1cx1HIlhqairdu3fn2muvpU6dOq7jiEg+0ICwcxg/fjxr167l008/pXjx4q7jSIRKSUlh69atdOnShUsvvdR1HBHJJ+qccxAfH0+/fv246667ePjhh13HkQh16tQpevToweWXX0716tVdxxGRfKTOOQdDhgzh6NGjjB49WiNixYmkpCR27NhBnz59dOUvkQikzjmbLVu28K9//Ytnn32Wm266yXUciUBJSUn07NmTihUrqjCLRCh1ztl069aNEiVKMHToUNdRJALFx8ezZcsWhg0bRtmyZV3HERFH1DlnMWfOHGJiYhgwYABXXHGF6zgSYdLT0xkwYAB16tRRYRaJcOqcvdLS0ujWrRu1a9fmpZdech1HIszhw4f58ccfGTVqFAULFnQdR0QcU+fs9e6777J582ZGjhxJkSJFXMeRCGKt5Z133qFZs2YqzCICqHMG4MiRIwwaNIiWLVvSpk0b13Ekguzbt49vvvmGwYMHu44iIkFEnTMwYMAAEhMTGTVqlE6dknxjrWXmzJl06NDBdRQRCTIR3zmvW7eOcePG8cILL1CvXj3XcSRC7Ny5k6lTp9KrVy/XUUQkCEV052ytpUuXLlxyySUMGjTIdRyJEKdPn2bNmjW6ZruInFNEd85ffvkl8+fP55133qFcuXKu40gE2LRpE5MmTWLYsGGuo4hIEIvYzvn06dO88sorXHfddTz//POu40gEOHDgAAkJCbz66quuo4hIkAurzvnw4cPMmDGDjIyMC867YsUK4uLi+PbbbylUKKxWgwShNWvWMHXqVF577TUKFIjYz8Qi4qOwqkrjxo2jf//+Ps/foUMHWrRoEcBEIrB+/XpKliypwiwiPgur4pyamgrAr7/+6tP8FSpUCGQcEVatWsXMmTMZOHCgTtMTEZ+FVXEGMMZQsWJF1zFEWLJkCVWrVlVhFpFc0z42kQDYvHkz33//PVWrVlVhFpFcU3EW8bO5c+dSoEABoqKiVJhF5KL4VJyNMfcbY7YYY7YbY855SSNjzMPGGGuMaeS/iCKh4+DBg2zevJk6deq4jiIiIeyCxdkYUxAYC7QC6gEdjDG/u86lMaY00Bn40d8hRULBjBkz2LVrFy+//LLrKCIS4nzpnG8Btltr46y1qcAnQLsc5nsVeB1I8WM+kZCQnJzMiRMnaNKkiesoIhIGfCnOlYE9Wab3eu87yxjTEKhqrZ3tx2wiIeHjjz9m3bp1dOrUyXUUEQkTeT6VyhhTABgJPO3DvM8Bz4HnHOPY2Nizj508efI30xdj165dAHleTjjyx/qV30tKSuKXX36hfv36Wr8Bom03sLR+Aycv69aX4rwPqJpluor3vjNKA/WBWO/I1IrATGNMW2vtyqwLsta+D7wP0KhRI9usWbOzj8XGxpJ1+mLMnz8fIM/LCUf+WL/yWx9++CHlypWjV69eWr8BpHUbWFq/gZOXdetLcV4B1DbGXIWnKLcHOp550FqbAFx2ZtoYEwt0z16YRcJJXFwcDRs25KabbnIdRUTC0AWPOVtr04EXgW+ATcA0a+0GY8wQY0zbQAcUCTZjx45lw4YNKswiEjA+HXO21sYAMdnuG3COeZvlPZZIcFq8eDGPPvooV1xxhesoIhLGdIUwER+99957pKWlqTCLSMCF3RdfiPibtZZPPvmEZ599lsKFC7uOIyIRQJ2zyAVMmTKFGjVqqDCLSL5R5yxyDpmZmbz99tt07tyZggULuo4jIhFEnbPIOcydO5c//OEPKswiku9UnEWyycjIoF+/ftx11100aNDAdRwRiUAqziJZZGRksGrVKh5//HFKlCjhOo6IRCgVZxGvtLQ0evToQfXq1bn22mtdxxGRCKYBYSLA6dOn2bZtGy+++KLOYxYR59Q5S8RLSUmhR48eXHLJJVx99dWu44iIqHOWyHbq1Cm2b99Or169qFSpkus4IiKAOmeJYCkpKfTs2ZMrrrhChVlEgoo6Z4lIJ06cYN26dQwbNowyZcq4jiMi8hvqnCXiZGZm0r9/f+rWravCLCJBSZ2zRJSjR4+yaNEiRo0aRYEC+mwqIsFJ704SUd59913uueceFWYRCWrqnCUiHDhwgC+//JL+/fu7jiIickFqHyTsWWuZNWsWTz75pOsoIiI+UecsYe2XX35h4sSJ6phFJKSoc5awlZKSwtq1a+nZs6frKCIiuaLiLGFp69atDBgwgD/+8Y8ULVrUdRwRkVxRcZaws3//fhISEhg2bBjGGNdxRERyTcVZwsq6desYPXo0DRs2pFAhDakQkdCkdy8JG+vXr6dYsWJER0frPGYRCWl6B5OwsH79eqZNm0bNmjVVmEUk5OldTELe0qVLKVmyJIMHD1ZhFpGwoHcyCWlxcXEsWLCAGjVqaPCXiIQNFWcJWd999x2nTp2id+/eKswiElZUnCUkHTt2jPXr11O/fn0VZhEJO2E1WvvUqVMULFjQdQwJsK+++oqyZcvSuXNn11FERAIirDrnBQsWcNttt7mOIQGUkpLCsWPHuPPOO11HEREJmLDpnA8cOMCqVasYNmyY6ygSINOmTaNYsWJ06tTJdRQRkYAKm+L89ddfA9C6dWvHSSQQTpw4QZkyZbj//vtdRxERCbiwKc4xMTFUqlSJG264wXUU8bP//ve/lChRgkcffdR1FBGRfBEWxTk9PZ25c+fyyCOPaORumNm2bRsNGzbk+uuvdx1FRCTfhMWAsKVLl5KQkKBd2mFm3LhxbNy4UYVZRCJOWHTOMTExFCpUiBYtWriOIn6yYMECHn74YS677DLXUURE8l1YdM4xMTE0bdqUMmXKuI4ifjB+/HjS0tJUmEUkYoV857xv3z7Wrl3LiBEjXEeRPLLWMnnyZJ5++ml9F7OIRLSQ75znzJkD6BSqcPDZZ59Ro0YNFWYRiXgh/y4YExND1apVqVevnusocpGstYwcOZKXX36ZwoULu44jIuJcSHfO6enpzJs3j9atW+sUqhC2YMEC7r77bhVmERGvkC7OiYmJJCYmUrduXddR5CJkZmbSr18/GjVqRKNGjVzHEREJGiG/WxtQ1xyCMjIyWLduHe3bt9coexGRbEK6c5bQlJaWRlRUFJdffjn169d3HUdEJOiERecsoSM1NZXt27fz/PPPU7lyZddxRESCkjpnyTenT5+mZ8+elChRgtq1a7uOIyIStEKuc166dCkffPAB1lpOnz7tOo74KDk5ma1bt9KjRw91zCIiFxBSxTkxMZGHHnqIkydPcskllwBw1VVX0aBBA8fJ5HzS0tLo0aMHvXv3VmEWEfFBSBXnYcOGceDAAX788UduueUW13HEB4mJiaxatYro6GhKly7tOo6ISEgImWPOcXFxjBw5kk6dOqkwhwhrLYMGDaJevXoqzCIiuRAynXP37t0pXLgw0dHRrqOID44fP863337LG2+8QYECIfMZUEQkKITEu+b8+fP54osv6NOnD5UqVXIdR3zw/vvv07JlSxVmEZGLEPSdc0ZGBl26dKFGjRp069bNdRy5gEOHDjFt2jSioqJcRxERCVlBX5wXLFjAunXrmDJlCsWKFXMdR87DWsvs2bP5y1/+4jqKiEhIC/riHBMTQ9GiRWnXrp3rKHIee/fu5f3332fIkCGuo4iIhLygPyAYExPDH/7wB0qUKOE6ipxDcnIy69evp0+fPq6jiIiEhaAuzjt27GDLli20atXKdRQ5hx07dtC3b1/uu+8+HXYQEfGToC7Oc+bMAaB169aOk0hO9u7dS0JCAq+//rq+tlNExI+CvjjXrl2bWrVquY4i2WzatIkxY8Zwww03ULhwYddxRETCStAW5+TkZObPn6+uOQht2LCBQoUKER0dTaFCQT+mUEQk5ARtcY6NjSUlJUXHm4PM5s2bmTJlCjVr1qRgwYKu44iIhKWgLc5z5syhePHi3H333a6jiNfy5cspWLAgQ4cO1ZW/REQCKCjfYc9czOKee+7RCOAgsXfvXr7++mtq1aqlwV8iIgEWlMV527ZtxMXFaZd2kFi4cCGHDh2if//+KswiIvkgKItzTEwMgIpzEEhMTGT16tU0aNBAhVlEJJ8E5VDb+fPnU6dOHa666irXUSLanDlzKFy4MF26dHEdRUQkogRl53zy5EkqVKjgOkZES01N5fDhw7Ro0cJ1FBGRiBOUnbO4NX36dDIzM+nUqZPrKCIiEUnFWX4jISGBUqVK0bJlS9dRREQiloqznDV58mQKFChAx44dXUcREYloKs4CeK781bBhQ+rVq+c6iohIxAvKAWGSvz744AM2bNigwiwiEiTUOUe47777jgcffJBy5cq5jiIiIl7qnCPYxIkTOX36tAqziEiQUeccoSZOnEjHjh31lY8iIkFInXMEmjlzJtWqVVNhFhEJUj4VZ2PM/caYLcaY7caYXjk83s0Ys9EYs9YY850xprr/o0peWWt56623uO+++2jWrJnrOCIicg4XbJ2MMQWBscC9wF5ghTFmprV2Y5bZVgONrLWnjDH/AEYAf/Y1xIEDBxgwYAAlSpQAYM2aNdSvXz8Xv4b4YsmSJTRt2pSiRYu6jiIiIufhS+d8C7DdWhtnrU0FPgHaZZ3BWrvAWnvKO7kMqJKbECtXrmTx4sXs3buX+Ph46tSpwyOPPJKbRch5ZGZm8uGHH3LttdfSpEkT13FEROQCfDnoWBnYk2V6L3C+d/hngDk5PWCMeQ54DqBChQrExsYCsG7dOgBeeuklrrnmmrPzn3lcLl5GRga7d++mcePGZ9ez+N/Jkye1vQaI1m1gaf0GTl7WrV9HBBljngAaAXfn9Li19n3gfYBGjRrZM8c9T548CcDNN99Mo0aN/BkpoqWnp9OnTx9eeOEFdu7cqePMARQbG6v1GyBat4Gl9Rs4eVm3vuzW3gdUzTJdxXvfbxhjWgB9gbbW2tMXlUb8Ji0tje3bt/PMM89QvbrG54mIhBJfivMKoLYx5ipjTBGgPTAz6wzGmAbAODyF+ZD/Y0pupKam0rNnTwoXLvybwwQiIhIaLrhb21qbbox5EfgGKAh8aK3dYIwZAqy01s4E3gBKAZ8aYwB2W2vbBjC3nENKSgqbN2+me/fuVK5c2XUcERG5CD4dc7bWxgAx2e4bkOV2Cz/nkouQkZFBz5496dGjhwqziEgI0yWiwkRSUhLLli0jOjqakiVLuo4jIiJ5oMt3hokhQ4ZQv359FWYRkTCgzjnExcfHM3v2bIYPH473eL+IiIQ4dc4h7oMPPqBVq1YqzCIiYUSdc4g6cuQIEydO5JVXXnEdRURE/Eydcwiy1vL111/zt7/9zXUUEREJABXnELN//3769OnDE088QenSpV3HERGRAFBxDiFJSUls3LiRAQMGXHhmEREJWSrOIWLXrl306dOH5s2bU7x4cddxREQkgFScQ8CZ77l+4403KFBAfzIRkXCnd/ogt3XrVkaNGsV1111HkSJFXMcREZF8oOIcxDZu3AjA66+/TuHChR2nERGR/KLiHKR27NjBxIkTqVmzJoUK6XR0EZFIouIchH766SdOnz7NsGHDKFiwoOs4IiKSz1Scg8yhQ4eYNWsW1157rQZ/iYhEKO0vDSLff/89hQoVYtCgQa6jiIiIQ2rNgkRycjIrVqygSZMmrqOIiIhj6pyDwLfffktqaipdu3Z1HUVERIKAOmfH0tLSOHjwIG3atHEdRUREgoQ6Z4dmzpzJyZMneeKJJ1xHERGRIKLi7Mjx48cpWbIkbdu2dR1FRESCjIqzA5988gmpqal06tTJdRQREQlCKs75bMOGDTRo0IBrrrnGdRQREQlSGhCWjyZOnMiGDRtUmEVE5LzUOeeTuXPn0q5dO8qWLes6ioiIBDl1zvngk08+4fTp0yrMIiLiE3XOAfbRRx/x+OOP6ysfRUTEZ+qcA+jrr7+mSpUqKswiIpIr6pwDwFrLW2+9xT/+8Q9KlizpOo6IiIQYdc5+Zq1lxYoV3HbbbSrMIiJyUVSc/SgzM5OBAwdSrVo17rjjDtdxREQkRKk4+0lmZiZbt27lT3/6ExUrVnQdR0REQpiKsx9kZGTQu3dvChUqRMOGDV3HERGREKcBYXmUnp7Ojh07+Mtf/kKtWrVcxxERkTCgzjkP0tLS6NmzJ8YY6tat6zqOiIiECXXOF+n06dNs2LCBV155hcqVK7uOIyIiYUSd80XIzMwkKiqK8uXLqzCLiIjfqXPOpVOnTrFo0SKio6MpXry46zgiIhKG1Dnn0muvvcaNN96owiwiIgGjztlHJ06c4IsvvmDo0KEYY1zHERGRMKbO2UcTJkygTZs2KswiIhJw6pwv4NixY4wfP56ePXu6jiIiIhFCnfN5ZGZm8u233/L888+7jiIiIhFExfkcDhw4QFRUFI899hhly5Z1HUdERCKIinMOEhMT2bx5M4MGDdIxZhERyXcqztns3r2bPn360LRpU30fs4iIOKHinMWePXuIj4/nzTffpFAhjZUTERE3VJy9duzYwahRo6hbty5FixZ1HUdERCKY2kNg8+bNALz++usULlzYcRoREYl0Ed857969mwkTJlC7dm0VZhERCQoR3TmvWbOGAgUKEB0dTYECEf85RUREgkTEVqT4+Hi++OIL6tevr8IsIiJBJSI752XLlpGamsrgwYNdRxEREfmdiGsZU1NTWbp0KXfeeafrVmMVQwAABwRJREFUKCIiIjmKqM55/vz5xMfH07VrV9dRREREziliOue0tDR+/fVXHnroIddRREREzisiOufZs2dz+PBhnn76addRRERELijsi/ORI0coWbIkbdq0cR1FRETEJ2FdnD/99FMSExP561//6jqKiIiIz8K2OK9du5YGDRpQq1Yt11FERERyJSwHhH388cesW7dOhVlEREJS2HXOc+bMoU2bNpQpU8Z1FBERkYsSVsX5888/p0CBAirMIiIS0sKmOH/00Ud06NBB38UsIiIhLyyOOc+fP5+KFSuqMIuISFgI6c7ZWsvIkSN59tlnKVu2rOs4IiIifhGynbO1lrVr19K4cWMVZhERCSshWZyttbz66qtceuml3HXXXa7jiIiI+FXI7dbOzMwkLi6OVq1aUa1aNddxRERE/C6kOufMzEz69etHWloajRs3dh1HREQkIEKmc87IyGDHjh088cQTXHvtta7jiIiIBExIdM7p6elERUWRkZFBvXr1XMcREREJqKDvnNPS0vj555955ZVXuPLKK13HERERCbig7pyttfTq1Yty5cqpMIuISMQI2s45JSWFefPm8dprr1GsWDHXcURERPJN0HbOI0aMoEGDBirMIiIScXwqzsaY+40xW4wx240xvXJ4vKgxZqr38R+NMTUuNtDJkyf54IMP6N+/P5UrV77YxYiIiISsCxZnY0xBYCzQCqgHdDDGZB8y/Qxw3FpbCxgFvH6xgSZNmkTbtm0xxlzsIkREREKaL53zLcB2a22ctTYV+ARol22edsB/vbc/A+4xF1FdP/zwQ/7xj39w+eWX5/apIiIiYcOX4lwZ2JNleq/3vhznsdamAwlA+dyGefTRR3P7FBERkbCTr6O1jTHPAc8BVKhQgdjYWMBzLvPAgQNJSko6e5/418mT/9/e3YTGUcdhHP8+WouItQaCIFhbhRYs9WDZQ71oRBHJIR4UqVC0UjxU9FDFkwdFj6IHQagRiygo6kUWVHrQhoAYMVAsbQ9StZao0PpWkKL48vPwH2RZmuw/Sedt9/nAwMzuZPjxMMxv5yXz/93Zlsj5lsfZlsv5lmc12eY05++BDT3L1xSfnW+dBUlrgPXAz/0biohpYBqg0+nExMTE/9+NjY3Ru2wX1szMjPMtkfMtj7Mtl/Mtz2qyzbms/QWwWdJ1ktYCO4Fu3zpd4MFi/l7gk4iIFVVkZmY24gaeOUfE35IeBQ4CFwMHIuKYpGeB+YjoAq8Bb0o6AfxCauBmZma2AqrrBFfSGeC7no/GgZ9qKWY0ON9yOd/yONtyOd/y9Ge7MSKy/h2ptubcT9J8RHTqrmNYOd9yOd/yONtyOd/yrCbbxr6+08zMbFS5OZuZmTVMk5rzdN0FDDnnWy7nWx5nWy7nW54VZ9uYe85mZmaWNOnM2czMzKihOVc5/OQoysj3cUnHJR2R9LGkjXXU2UaDsu1Z7x5JIclPwC5DTr6S7iv232OS3qq6xrbKOC5cK+mQpMPFsWGyjjrbSNIBSaclHV3ke0l6qcj+iKTtWRuOiMom0ktMvgauB9YCXwJb+9Z5BNhfzO8E3qmyxjZPmfneBlxWzO91vhcu22K9dcAsMAd06q67LVPmvrsZOAyMFctX1V13G6bMbKeBvcX8VuBk3XW3ZQJuAbYDRxf5fhL4CBCwA/g8Z7tVnzlXNvzkiBqYb0QciohzxeIc6V3pNljOvgvwHGk88z+qLG4I5OT7MPByRPwKEBGnK66xrXKyDeCKYn498EOF9bVaRMyS3oy5mLuBNyKZA66UdPWg7VbdnCsbfnJE5eTbaw/pF50NNjDb4nLVhoj4oMrChkTOvrsF2CLpU0lzku6qrLp2y8n2GWCXpAXgQ+CxakobCcs9LgMVDxlpzSFpF9ABbq27lmEg6SLgRWB3zaUMszWkS9sTpCs+s5JujIjfaq1qONwPvB4RL0i6mTRWwraI+LfuwkZV1WfOyxl+kqWGn7TzyskXSXcATwFTEfFnRbW13aBs1wHbgBlJJ0n3lrp+KCxbzr67AHQj4q+I+Bb4itSsbWk52e4B3gWIiM+AS0nvhbbVyzou96u6OXv4yXINzFfSTcArpMbse3b5lsw2Is5GxHhEbIqITaT7+VMRMV9Pua2Tc2x4n3TWjKRx0mXub6ossqVysj0F3A4g6QZScz5TaZXDqws8UDy1vQM4GxE/DvqjSi9rh4efLFVmvs8DlwPvFc/ZnYqIqdqKbonMbG2FMvM9CNwp6TjwD/BkRPiq2gCZ2T4BvCppH+nhsN0+Kcoj6W3Sj8bx4p7908AlABGxn3QPfxI4AZwDHsrarvM3MzNrFr8hzMzMrGHcnM3MzBrGzdnMzKxh3JzNzMwaxs3ZzMysYdyczczMGsbN2czMrGHcnM3MzBrmP+g7sPS1CiDKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# model_1 = Sequential([\n",
    "#     Dense(8, input_shape=(8,), activation=\"relu\"),\n",
    "#     Dense(4, input_shape=(8,), activation=\"relu\"),\n",
    "#     Dense(1, activation=\"sigmoid\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.8079 - accuracy: 0.4115 - val_loss: 0.7650 - val_accuracy: 0.4948\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.7981 - accuracy: 0.4236 - val_loss: 0.7564 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.7887 - accuracy: 0.4323 - val_loss: 0.7483 - val_accuracy: 0.5104\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.7799 - accuracy: 0.4410 - val_loss: 0.7406 - val_accuracy: 0.5156\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.7715 - accuracy: 0.4514 - val_loss: 0.7334 - val_accuracy: 0.5208\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.7635 - accuracy: 0.4601 - val_loss: 0.7265 - val_accuracy: 0.5260\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.7560 - accuracy: 0.4688 - val_loss: 0.7200 - val_accuracy: 0.5312\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.7488 - accuracy: 0.4740 - val_loss: 0.7138 - val_accuracy: 0.5521\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.7420 - accuracy: 0.4809 - val_loss: 0.7080 - val_accuracy: 0.5625\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.7355 - accuracy: 0.4896 - val_loss: 0.7025 - val_accuracy: 0.5781\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.7293 - accuracy: 0.5122 - val_loss: 0.6972 - val_accuracy: 0.5833\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.7235 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5938\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.7179 - accuracy: 0.5260 - val_loss: 0.6873 - val_accuracy: 0.6042\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.7125 - accuracy: 0.5347 - val_loss: 0.6827 - val_accuracy: 0.6094\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.7072 - accuracy: 0.5399 - val_loss: 0.6782 - val_accuracy: 0.6302\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.7022 - accuracy: 0.5521 - val_loss: 0.6740 - val_accuracy: 0.6458\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.6974 - accuracy: 0.5660 - val_loss: 0.6698 - val_accuracy: 0.6510\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6927 - accuracy: 0.5747 - val_loss: 0.6659 - val_accuracy: 0.6510\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.40 - 0s 26us/step - loss: 0.6882 - accuracy: 0.5885 - val_loss: 0.6621 - val_accuracy: 0.6510\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6838 - accuracy: 0.5920 - val_loss: 0.6583 - val_accuracy: 0.6562\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6795 - accuracy: 0.5990 - val_loss: 0.6547 - val_accuracy: 0.6615\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6754 - accuracy: 0.6059 - val_loss: 0.6513 - val_accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6715 - accuracy: 0.6198 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6677 - accuracy: 0.6337 - val_loss: 0.6447 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6640 - accuracy: 0.6441 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6604 - accuracy: 0.6562 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6569 - accuracy: 0.6597 - val_loss: 0.6354 - val_accuracy: 0.6771\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6535 - accuracy: 0.6701 - val_loss: 0.6325 - val_accuracy: 0.6875\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6502 - accuracy: 0.6719 - val_loss: 0.6296 - val_accuracy: 0.6979\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6470 - accuracy: 0.6771 - val_loss: 0.6269 - val_accuracy: 0.6927\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6439 - accuracy: 0.6840 - val_loss: 0.6242 - val_accuracy: 0.7031\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6409 - accuracy: 0.6892 - val_loss: 0.6216 - val_accuracy: 0.7031\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6379 - accuracy: 0.6910 - val_loss: 0.6190 - val_accuracy: 0.7083\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6351 - accuracy: 0.6979 - val_loss: 0.6165 - val_accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6323 - accuracy: 0.7014 - val_loss: 0.6141 - val_accuracy: 0.7083\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6296 - accuracy: 0.7049 - val_loss: 0.6118 - val_accuracy: 0.7031\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.6270 - accuracy: 0.7049 - val_loss: 0.6095 - val_accuracy: 0.7083\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.6245 - accuracy: 0.7101 - val_loss: 0.6074 - val_accuracy: 0.7188\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6220 - accuracy: 0.7118 - val_loss: 0.6052 - val_accuracy: 0.7188\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6196 - accuracy: 0.7153 - val_loss: 0.6032 - val_accuracy: 0.7240\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.6173 - accuracy: 0.7170 - val_loss: 0.6011 - val_accuracy: 0.7240\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.6150 - accuracy: 0.7170 - val_loss: 0.5991 - val_accuracy: 0.7240\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.6128 - accuracy: 0.7153 - val_loss: 0.5972 - val_accuracy: 0.7188\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.6106 - accuracy: 0.7135 - val_loss: 0.5953 - val_accuracy: 0.7188\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.6084 - accuracy: 0.7153 - val_loss: 0.5934 - val_accuracy: 0.7292\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.6063 - accuracy: 0.7170 - val_loss: 0.5916 - val_accuracy: 0.7292\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6042 - accuracy: 0.7205 - val_loss: 0.5898 - val_accuracy: 0.7344\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6022 - accuracy: 0.7274 - val_loss: 0.5881 - val_accuracy: 0.7344\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.6002 - accuracy: 0.7292 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5982 - accuracy: 0.7326 - val_loss: 0.5847 - val_accuracy: 0.7448\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5963 - accuracy: 0.7326 - val_loss: 0.5830 - val_accuracy: 0.7396\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5944 - accuracy: 0.7344 - val_loss: 0.5814 - val_accuracy: 0.7396\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.5925 - accuracy: 0.7326 - val_loss: 0.5798 - val_accuracy: 0.7344\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5907 - accuracy: 0.7361 - val_loss: 0.5782 - val_accuracy: 0.7396\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.5889 - accuracy: 0.7344 - val_loss: 0.5767 - val_accuracy: 0.7396\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5872 - accuracy: 0.7361 - val_loss: 0.5751 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.5854 - accuracy: 0.7378 - val_loss: 0.5737 - val_accuracy: 0.7396\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5837 - accuracy: 0.7361 - val_loss: 0.5722 - val_accuracy: 0.7448\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5821 - accuracy: 0.7361 - val_loss: 0.5708 - val_accuracy: 0.7396\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5804 - accuracy: 0.7378 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5788 - accuracy: 0.7378 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5772 - accuracy: 0.7361 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5756 - accuracy: 0.7378 - val_loss: 0.5652 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5741 - accuracy: 0.7361 - val_loss: 0.5639 - val_accuracy: 0.7552\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5725 - accuracy: 0.7361 - val_loss: 0.5626 - val_accuracy: 0.7552\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5710 - accuracy: 0.7344 - val_loss: 0.5613 - val_accuracy: 0.7552\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5695 - accuracy: 0.7344 - val_loss: 0.5601 - val_accuracy: 0.7552\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5680 - accuracy: 0.7361 - val_loss: 0.5589 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5666 - accuracy: 0.7361 - val_loss: 0.5577 - val_accuracy: 0.7552\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5652 - accuracy: 0.7361 - val_loss: 0.5565 - val_accuracy: 0.7552\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5637 - accuracy: 0.7344 - val_loss: 0.5553 - val_accuracy: 0.7552\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5623 - accuracy: 0.7344 - val_loss: 0.5542 - val_accuracy: 0.7552\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5609 - accuracy: 0.7361 - val_loss: 0.5530 - val_accuracy: 0.7552\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5596 - accuracy: 0.7378 - val_loss: 0.5519 - val_accuracy: 0.7552\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5582 - accuracy: 0.7396 - val_loss: 0.5508 - val_accuracy: 0.7552\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5569 - accuracy: 0.7413 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5556 - accuracy: 0.7431 - val_loss: 0.5487 - val_accuracy: 0.7552\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5543 - accuracy: 0.7448 - val_loss: 0.5476 - val_accuracy: 0.7552\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5530 - accuracy: 0.7465 - val_loss: 0.5466 - val_accuracy: 0.7604\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5518 - accuracy: 0.7483 - val_loss: 0.5456 - val_accuracy: 0.7604\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5505 - accuracy: 0.7483 - val_loss: 0.5446 - val_accuracy: 0.7604\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5493 - accuracy: 0.7500 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5481 - accuracy: 0.7465 - val_loss: 0.5426 - val_accuracy: 0.7604\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5468 - accuracy: 0.7465 - val_loss: 0.5416 - val_accuracy: 0.7708\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.5457 - accuracy: 0.7465 - val_loss: 0.5407 - val_accuracy: 0.7708\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5445 - accuracy: 0.7465 - val_loss: 0.5398 - val_accuracy: 0.7708\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5433 - accuracy: 0.7483 - val_loss: 0.5388 - val_accuracy: 0.7708\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5422 - accuracy: 0.7483 - val_loss: 0.5379 - val_accuracy: 0.7708\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5411 - accuracy: 0.7483 - val_loss: 0.5371 - val_accuracy: 0.7708\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5400 - accuracy: 0.7483 - val_loss: 0.5362 - val_accuracy: 0.7708\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5389 - accuracy: 0.7483 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5378 - accuracy: 0.7465 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5368 - accuracy: 0.7465 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5357 - accuracy: 0.7465 - val_loss: 0.5328 - val_accuracy: 0.7708\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5347 - accuracy: 0.7465 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5337 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.7656\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5327 - accuracy: 0.7483 - val_loss: 0.5305 - val_accuracy: 0.7656\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5317 - accuracy: 0.7483 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5307 - accuracy: 0.7483 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5298 - accuracy: 0.7483 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5288 - accuracy: 0.7483 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5279 - accuracy: 0.7483 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5270 - accuracy: 0.7483 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5260 - accuracy: 0.7465 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5252 - accuracy: 0.7465 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.5243 - accuracy: 0.7448 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5234 - accuracy: 0.7448 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5225 - accuracy: 0.7448 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5216 - accuracy: 0.7448 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5208 - accuracy: 0.7448 - val_loss: 0.5213 - val_accuracy: 0.7708\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5200 - accuracy: 0.7448 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5191 - accuracy: 0.7448 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 21us/step - loss: 0.5183 - accuracy: 0.7448 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5175 - accuracy: 0.7448 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.5167 - accuracy: 0.7448 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.5159 - accuracy: 0.7465 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.5151 - accuracy: 0.7483 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5136 - accuracy: 0.7500 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5128 - accuracy: 0.7483 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.5121 - accuracy: 0.7483 - val_loss: 0.5149 - val_accuracy: 0.7760\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5114 - accuracy: 0.7483 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5107 - accuracy: 0.7500 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5093 - accuracy: 0.7500 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5086 - accuracy: 0.7535 - val_loss: 0.5124 - val_accuracy: 0.7812\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.5079 - accuracy: 0.7535 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5072 - accuracy: 0.7552 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.5066 - accuracy: 0.7552 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5059 - accuracy: 0.7569 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5053 - accuracy: 0.7569 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5046 - accuracy: 0.7569 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5040 - accuracy: 0.7569 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5034 - accuracy: 0.7569 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.5028 - accuracy: 0.7569 - val_loss: 0.5083 - val_accuracy: 0.7812\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5022 - accuracy: 0.7552 - val_loss: 0.5079 - val_accuracy: 0.7812\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5016 - accuracy: 0.7552 - val_loss: 0.5075 - val_accuracy: 0.7812\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5010 - accuracy: 0.7569 - val_loss: 0.5071 - val_accuracy: 0.7812\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.5005 - accuracy: 0.7569 - val_loss: 0.5067 - val_accuracy: 0.7865\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4999 - accuracy: 0.7569 - val_loss: 0.5063 - val_accuracy: 0.7865\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4993 - accuracy: 0.7569 - val_loss: 0.5060 - val_accuracy: 0.7865\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4988 - accuracy: 0.7569 - val_loss: 0.5056 - val_accuracy: 0.7865\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4982 - accuracy: 0.7569 - val_loss: 0.5052 - val_accuracy: 0.7865\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5049 - val_accuracy: 0.7865\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4971 - accuracy: 0.7587 - val_loss: 0.5045 - val_accuracy: 0.7865\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4966 - accuracy: 0.7604 - val_loss: 0.5042 - val_accuracy: 0.7865\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4955 - accuracy: 0.7622 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4950 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5028 - val_accuracy: 0.7865\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5025 - val_accuracy: 0.7917\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4935 - accuracy: 0.7639 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4930 - accuracy: 0.7639 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4916 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5008 - val_accuracy: 0.7865\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4907 - accuracy: 0.7622 - val_loss: 0.5005 - val_accuracy: 0.7865\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4902 - accuracy: 0.7622 - val_loss: 0.5002 - val_accuracy: 0.7865\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4898 - accuracy: 0.7622 - val_loss: 0.5000 - val_accuracy: 0.7865\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4893 - accuracy: 0.7639 - val_loss: 0.4997 - val_accuracy: 0.7865\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7865\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4885 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7865\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4881 - accuracy: 0.7639 - val_loss: 0.4990 - val_accuracy: 0.7865\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4876 - accuracy: 0.7639 - val_loss: 0.4987 - val_accuracy: 0.7865\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4872 - accuracy: 0.7639 - val_loss: 0.4985 - val_accuracy: 0.7865\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4868 - accuracy: 0.7639 - val_loss: 0.4982 - val_accuracy: 0.7865\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4864 - accuracy: 0.7639 - val_loss: 0.4980 - val_accuracy: 0.7917\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 23us/step - loss: 0.4860 - accuracy: 0.7639 - val_loss: 0.4978 - val_accuracy: 0.7917\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4856 - accuracy: 0.7622 - val_loss: 0.4976 - val_accuracy: 0.7917\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4852 - accuracy: 0.7639 - val_loss: 0.4974 - val_accuracy: 0.7917\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.4972 - val_accuracy: 0.7917\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4845 - accuracy: 0.7639 - val_loss: 0.4970 - val_accuracy: 0.7917\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4842 - accuracy: 0.7622 - val_loss: 0.4968 - val_accuracy: 0.7917\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4838 - accuracy: 0.7622 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4834 - accuracy: 0.7639 - val_loss: 0.4964 - val_accuracy: 0.7917\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4831 - accuracy: 0.7639 - val_loss: 0.4962 - val_accuracy: 0.7917\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4827 - accuracy: 0.7622 - val_loss: 0.4961 - val_accuracy: 0.7917\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4824 - accuracy: 0.7639 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4821 - accuracy: 0.7639 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4817 - accuracy: 0.7639 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4814 - accuracy: 0.7639 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4811 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4801 - accuracy: 0.7674 - val_loss: 0.4948 - val_accuracy: 0.7812\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4798 - accuracy: 0.7674 - val_loss: 0.4947 - val_accuracy: 0.7812\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4795 - accuracy: 0.7674 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7865\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7865\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7865\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4930 - val_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53377557],\n",
       "       [0.5222594 ],\n",
       "       [0.3089299 ],\n",
       "       [0.24482542],\n",
       "       [0.23796025],\n",
       "       [0.3859728 ],\n",
       "       [0.12824556],\n",
       "       [0.24500224],\n",
       "       [0.94219923],\n",
       "       [0.18733074]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.827\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14ae3b470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4929 - val_accuracy: 0.7812\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.4928 - val_accuracy: 0.7812\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4925 - val_accuracy: 0.7865\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4924 - val_accuracy: 0.7865\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.4923 - val_accuracy: 0.7865\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7865\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7917\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4736 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7917\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.4918 - val_accuracy: 0.7917\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7917\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4729 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4727 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4726 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7865\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4723 - accuracy: 0.7708 - val_loss: 0.4913 - val_accuracy: 0.7865\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.4912 - val_accuracy: 0.7865\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7865\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7865\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7865\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7865\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7865\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7865\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4708 - accuracy: 0.7691 - val_loss: 0.4907 - val_accuracy: 0.7865\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4705 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7865\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7865\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4702 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7865\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7865\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7917\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4694 - accuracy: 0.7708 - val_loss: 0.4902 - val_accuracy: 0.7917\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7917\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4691 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7917\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4901 - val_accuracy: 0.7917\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4899 - val_accuracy: 0.7917\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4899 - val_accuracy: 0.7917\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7917\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7917\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4674 - accuracy: 0.7691 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4671 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4669 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4668 - accuracy: 0.7691 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4666 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7917\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7917\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4643 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4642 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4640 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4639 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4637 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 22us/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4589 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4587 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4586 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4576 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4569 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7865\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4560 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 19us/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4551 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4550 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4548 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4548 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7812\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7812\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7812\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7812\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4540 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4539 - accuracy: 0.7760 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4538 - accuracy: 0.7760 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4535 - accuracy: 0.7760 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4527 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4527 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4525 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4524 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4524 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4524 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4522 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4522 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4519 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4519 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4517 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4517 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4512 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4512 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 19us/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4510 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4509 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4506 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4506 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4498 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4496 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4496 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4496 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4495 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4494 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4494 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4493 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4493 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4492 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4492 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4491 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4488 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4488 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4488 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4487 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4478 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4478 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4475 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4474 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4474 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4474 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4474 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4473 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4472 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4472 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7760\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4472 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7760\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.4915 - val_accuracy: 0.7760\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4470 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4445 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4445 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4445 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4442 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4435 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4435 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4435 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4434 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4434 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4430 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4430 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4430 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4426 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4426 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4393 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4348 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4346 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4346 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4346 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4342 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4341 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4341 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4339 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4338 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4337 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4337 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4336 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5105 - accuracy: 0.75 - 0s 21us/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4333 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4333 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 25us/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4327 - accuracy: 0.7917 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4323 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 19us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 22us/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 21us/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7865\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14aee0c18>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here to with layer 1,2 having activation relu and layer 3 with activation sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here to plot the loss accuracy and ROC curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
